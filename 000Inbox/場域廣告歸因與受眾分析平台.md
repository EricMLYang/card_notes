# 場域廣告歸因與受眾分析平台

---

## 第一部分：功能溝通

#### 1\. 核心意圖 (Core Intent)

本系統旨在建立一個閉環的數據生態系，通過整合**播放數據**、**感應器行為數據**與**客戶銷售數據**，動態地識別高價值的受眾輪廓，並驗證「人流（觀看）」到「金流（購買）」的轉化效果，藉此優化廣告投放策略。

---

### 2\. 數據資產與維度定義 (Data Assets & Schema Concept)

*給工程師/架構師：我們需要建立高擴展性的 Schema，以應對未來傳感器或標籤的動態新增。*

#### A. 受眾數據中心 (Audience Hub) - `id_segmentation`

這是分析的主鍵 (Primary Key)，聚合了多維度的標籤：

- **靜態屬性 (Static Dimensions):**

   - 基礎識別：店鋪 ID (Store ID)、設備 ID (Device ID)。

   - 時空標籤：固定時段 (Time Slots)。

- **動態環境屬性 (Contextual Dimensions):**

   - **高動態性：** 需支援外部 API 注入（如：天氣 API、商圈活動事件）。

   - **粒度彈性：** 支援店鋪區域 (Zone) 或商圈 (District) 等不同層級的聚合。

- **行為屬性 (Behavioral Attributes) - *源於感應器*:**

   - **指標：** 觀看時長 (Dwell Time)、注視次數 (Gaze Count)、人流顯著性。

   - **擴充性需求：** 架構需預留接口，當安裝新感應器（如 AI 攝影機、Wi-Fi 探針）時，能自動將新產生的行為數據抽象化為新的 Attribute 欄位，無需重構大表。

#### B. 內容數據中心 (Content Hub)

- **廣告元數據 (Ad Metadata):** 產品類型 (Category)、影片情境/色調 (Context/Tone)、促銷屬性 (Promo Tags)。

#### C. 轉化數據中心 (Conversion Hub) - *高敏感度*

- **銷售數據 (Sales Data):** 客戶端的 POS/ERP 數據。

- **關鍵技術限制：** 數據所有權屬於客戶，需透過 **Data Clean Room (數據無塵室)** 技術進行整合，確保在不洩露原始個資/交易明細的前提下進行交集分析。

---

### 3\. 核心分析邏輯與應用 (Analytical Logic & Application)

*給分析師：我們不是要死板的報表，而是要「滾動式」的模型與洞察。*

#### A. 受眾包特徵工程 (Audience Bucket Strategy)

- **意圖：** 找出「對指標有意義」的變數組合。

- **邏輯：** 系統需具備 Feature Selection 能力。

   - *Input:* 所有標籤（靜態+動態+行為）。

   - *Target:* 觀看或逗留。

   - *Output:* 自動挖掘出顯著特徵（例如：「下雨天+A區+男性」是一個高停留受眾包）。

- **維運要求：** 當新標籤（新感應器數據）進入時，模型需重新訓練或驗證，以納入新變數。

#### B. 廣告內容媒合分析 (Content-Audience Fit)

- **意圖：** 驗證什麼人看什麼內容會「停留更久」。

- **分析模型：** 相關性分析 (Correlation) 或 歸因分析。

   - 公式概念：`f(id_segmentation, Ad_Content_Tags) -> Engagement_Score (Significant Uplift)`

   - 應用：自動標記出「黃金組合」（例：年輕男性受眾 + 運動飲料廣告 = 觀看時間提升 30%）。

#### C. 銷售提升歸因 (Sales Uplift Analysis)

- **意圖：** 驗證看了廣告是否真的「買更多」。

- **分析模型：** Uplift Modeling (增益模型) 或 A/B Test 邏輯對照。

   - 比較「看過廣告的受眾包」與「未看過/看其他廣告的受眾包」在銷售數據上的差異。

- **執行頻率：** 定期滾動分析 (Rolling Basis)，監控長期趨勢。

---

### 4\. 給技術團隊的關鍵提問 (Discussion Starters)

**對 Data Engineer / Architect：**

> 「考慮到我們的『行為屬性』會隨著新感應器不斷增加，目前的 Data Schema 設計是否支援**動態欄位擴充 (Schema Evolution)**？我們是否需要 NoSQL 或特定的 Data Lake 結構來處理這種非結構化轉結構化的過程？」



**對 Data Analyst / Scientist：**

> 「關於『受眾包』的顯著性分析，我們如何設計一個**自動化的特徵篩選機制**？因為標籤會變多，我希望系統能主動告訴我哪些標籤現在變重要了，而不是每次都人工跑回歸分析。」



**對 Backend / Security Engineer：**

> 「關於第 3 點的銷售數據，我們需要引入 **Clean Room** 的概念。目前的架構能否支援在『不將客戶原始數據落地到我們主庫』的情況下，進行 ID Mapping 和成效計算？」

---

### 顧問總結與建議

這份需求的核心難點在於 **「動態性」** 與 **「隱私性」**：

1. **動態性：** 感應器會變、環境標籤會變，系統不能寫死。

2. **隱私性：** 涉及客戶銷售數據，Data Clean Room 是建立信任的關鍵。

**這張圖對於解釋第 3 點至關重要。** 它可以幫助你說明如何讓客戶在「不給出明細」的情況下，讓兩邊的數據（廣告數據 vs. 銷售數據）進行安全的碰撞分析。

---





## 第二部分：可能的技術規劃清單 ( 還沒針對以上目的設計）

### 1\. Delta Table 動態標籤系統的核心設計模式

SchemaEvolution: Databricks Runtime 15.4+ 支援 MERGE 操作中的 schema 演進，允許在 upsert 時同時處理新欄位

```python
from delta.tables import DeltaTable

# 啟用 MERGE 時的 Schema Evolution
(targetTable
  .merge(sourceDF, "source.user_id = target.user_id")
  .withSchemaEvolution()  # 關鍵設定
  .whenMatchedUpdateAll()
  .whenNotMatchedInsertAll()
  .execute())
```



混合設計，高頻查詢的核心標籤設為固定欄位（支援 data skipping），動態標籤則使用 Map 欄位存儲：

```python
CREATE TABLE audience_tags_hybrid (
    user_id STRING,
    -- 核心標籤：固定欄位，支援 Z-Order 優化
    segment_id STRING,
    loyalty_tier STRING,
    purchase_frequency INT,
    -- 動態標籤：Map 欄位，無需 Schema 變更
    custom_tags MAP<STRING, STRING>,
    computed_scores MAP<STRING, DOUBLE>,
    -- 元數據
    updated_at TIMESTAMP,
    tag_version INT
) USING DELTA
PARTITIONED BY (segment_id)
TBLPROPERTIES (
    'delta.enableChangeDataFeed' = 'true',
    'delta.autoOptimize.optimizeWrite' = 'true'
);
```

搭配獨立的 Tag Registry 表管理標籤定義與計算邏輯，實現真正的「可插拔」：

```python
class TagComputer:
    def __init__(self, spark, tag_registry_table):
        self.spark = spark
        self.tag_registry = spark.table(tag_registry_table)
    
    def compute_tag(self, tag_id: str, source_df):
        """動態載入標籤計算邏輯"""
        tag_def = self.tag_registry.filter(f"tag_id = '{tag_id}'").first()
        return source_df.selectExpr(f"{tag_def.computation_logic} as {tag_def.tag_name}")
```



高維度稀疏數據的存儲優化

受眾標籤數據本質上是高度稀疏的（High-Dimensional Sparse Data）。一個用戶可能擁有數千個潛在標籤中的寥寥數個。若將每個標籤都存儲為獨立的物理欄位，將造成存儲空間的浪費與查詢效能的低落。

為了在保留查詢能力的同時優化存儲，可採用 Map Type 或 Variant Type 來存儲標籤 。  

- Map Type 實作： 將標籤存儲為 `Map<String, String>` 格式（例如 `tags: {'time': 'afternoon', 'region': 'north'}`）。這允許單一欄位容納無限擴展的標籤鍵值對，且現代查詢引擎（如 Spark SQL, Photon）已針對 Map 類型的鍵值查找進行了高度優化 。  

- JSON 字串與 Variant： 對於更複雜的巢狀結構，利用 Delta Lake 的 JSON 支援或 Snowflake 的 Variant 類型，可以在不犧牲 Schema 靈活性的情況下，保持對子欄位的查詢性能 。





## 2\.Databricks Clean Rooms 和 Lakehouse Federation

運作模式：無信任與隔離運算 (No-Trust & Isolation)

- 架構拓樸：採用 Hub-and-Spoke 模式。運算不發生在雙方環境，而是在 Databricks 託管的 Central Clean Room (Serverless Compute) 中進行。

- 權限控制：雙方地位平等（包含發起者），無 Super Admin。

- 數據隱私：雙方無法存取彼此原始數據（Raw Data），僅能查看 Schema。

- 執行控管：所有程式碼（Notebooks）必須經由合作方審核 (Approve) 後，才能在隔離環境中執行。

外部數據解決方案：Lakehouse Federation (關鍵技術)

- Zero-ETL：數據不需要透過 ETL 搬移或複製到 Databricks 儲存層 (S3/ADLS)。

- 虛擬化存取：透過 Lakehouse Federation 技術，將外部資料庫 (Snowflake, PostgreSQL, SQL Server 等) 掛載為 Unity Catalog 中的 Foreign Catalog。

- 查詢下推 (Query Pushdown)：分析時，Databricks 引擎將查詢翻譯並下推至源頭資料庫執行，僅回傳運算所需的結果集至 Clean Room。

實作流程 (Implementation Steps)

1. 建立連線 (Connection)：在 Unity Catalog 中設定指向外部資料庫的 Connection (包含認證資訊)。

2. 掛載目錄 (Foreign Catalog)：將外部 Database 映射為 Unity Catalog 的 Foreign Catalog (e.g., `snowflake_db` -> `uc_foreign_catalog`)。

3. 加入淨室 (Add to Clean Room)：直接選擇 Foreign Catalog 中的 Tables/Views 加入 Clean Room 資產清單。

4. 協作分析：合作方在 Clean Room 針對該 Table 寫 SQL/Python 時，系統自動經由 Federation 抓取數據。

安全與治理 (Security & Governance)

- 統一治理：由 Unity Catalog 統一管理外部數據的權限與稽核 (Audit Logs)，無需在外部資料庫另外設定複雜的分享權限。

- 安全傳輸：數據進入中央淨室的過程採用 Delta Sharing 協議（基於 REST 的安全開源協議），確保傳輸加密。



分析手法：

廣告歸因的安全匹配流程實作：在 Databricks Clean Room 環境中執行廣告歸因分析：

**盲匹配 (Blind Match)：** 雙方上傳經過加鹽雜湊（Salted Hash）的識別碼（如 Email Hash, Mobile AD ID）



自建差分隱私層強化保護：由於 Databricks Clean Rooms 目前未內建差分隱私，建議自行實作隱私保護層：添加拉普拉斯噪聲實現差分隱私, 帶差分隱私的安全聚合



Uplift Modeling 在 Clean Room 環境的技術實現

Uplift Modeling 的核心是識別 Persuadables——只因被定向而產生轉換的用戶群體。 Wikipedia 在 Clean Room 環境中，需同時滿足隱私保護與因果推斷的需求。

四類受眾分群與定向策略

| 類型 | 定義 | 行銷策略 | 
|---|---|---|
| Persuadables | 只因廣告曝光而轉換 | 高優先級定向，最大化 ROI | 
| **Sure Things** | 無論是否曝光都會轉換 | 避免浪費預算 | 
| **Lost Causes** | 無論如何都不會轉換 | 排除定向 | 
| **Sleeping Dogs** | 曝光後反而不轉換 | 絕對避免定向 | 

---



基於 Causal Forests 的異質性處理效果 (HTE) 估計

演算法優勢： 傳統迴歸模型假設處理效果是均勻的，而 Causal Forests 專為捕捉 異質性 (Heterogeneity) 而設計。它構建大量的決策樹（Honest Trees），其分裂標準（Splitting Criterion）不是為了最小化預測誤差，而是為了最大化子節點間處理效果的差異



CausalML 框架實作

from causalml.inference.meta import XGBTRegressor 

from causalml.metrics import plot_gain



Clean Room 內的 A/B Testing 框架

```sql
-- Databricks SQL：多變數測試分析（符合隱私閾值）
WITH experiment_results AS (
    SELECT
        audience_segment,
        video_content_type,
        creative_variant,
        COUNT(DISTINCT user_id) as unique_users,
        SUM(conversions) as total_conversions,
        SUM(revenue) as total_revenue
    FROM clean_room_experiment_log
    WHERE experiment_id = 'mvt_2024_q4'
    GROUP BY 1, 2, 3
    HAVING COUNT(DISTINCT user_id) >= 100  -- 隱私保護閾值
)
SELECT
    audience_segment,
    video_content_type,
    creative_variant,
    unique_users,
    total_conversions / unique_users as conversion_rate,
    total_revenue / unique_users as revenue_per_user
FROM experiment_results
ORDER BY conversion_rate DESC;
```





## 第三部分：Databricks 資料和技術規劃

1\.Delta Table 設計說明 

2\.Delta Table Schema 設計建模 (多標籤動態適應）

3\.受眾輪廓與廣告觀看分析機制 ( Pipeline 化）

4\.Data Clean Room

5\.銷售 Uplift 安全比對 



## 第三部分：Databricks 資料和技術規劃（先求好溝通、可落地）

> 目標：先把「受眾 × 場域 × 廣告 × 行為」在 Databricks Lakehouse 裡變成**可追溯、可擴充、可迭代**的資料資產；銷售歸因（Clean Room）先用**彙總層**接起來，避免一開始就做太重。

---

# 1\. Delta Table 設計說明

### 1\.1 設計原則（你可以直接拿去跟工程師對齊）

1. **事件先落地、再標準化**：所有來源（CMS、AI Camera、WiFi…）先進「原始事件表」，不要一開始就把欄位設死。

2. **一切可回放（replayable）**：任何彙總與模型特徵都要能從事件表重算（避免口水戰）。

3. **核心查詢快 + 長尾彈性**：常用標籤做固定欄位，長尾標籤走 Map/JSON。

4. **增量更新（incremental）優先**：用 `MERGE` + 去重鍵（event_id / exposure_id）讓資料每天滾動更新。

5. **治理先有邊界**：Unity Catalog 用 catalog/schema 切開「原始」「分析」「對外分享 / clean room」的資產範圍。

---

### 1\.2 建議的 Lakehouse 分層（最直覺的溝通方式）

- **Bronze（原始事件層）**：只做最小清理（欄位型別、必要欄位），保留最大彈性

- **Silver（標準整併層）**：跨來源對齊 key、時間、device/store/person 定義

- **Gold（分析資產層）**：受眾包、廣告成效、內容媒合、（未來）uplift 特徵與結果

> 你現在的文件第一部分（Audience / Content / Conversion Hub）基本上就是 Gold 的語言；第三部分要做的是把 Bronze/Silver/Gold 的表設計起來。

---

### 1\.3 Delta Table 的「規劃固定答案」：你們為什麼要用它

- **ACID + MERGE**：事件去重、補資料、晚到資料（late arrival）都能用 `MERGE` 解

- **Schema Evolution（結構演進）**：新欄位可以逐步加，不必重建整張表

- **Time Travel（版本回溯）**：出問題可以追到「是哪一天哪一次寫入」

- **Change Data Feed（CDF，可選）**：下游（特徵表/報表/服務）只吃變更，不用全量重算

- **檔案層最佳化（OPTIMIZE / Liquid Clustering，可後續）**：針對常用查詢 key 做加速

---

### 1\.4 實務上「表該怎麼切」：先從 6 張表就能跑起 MVP

下面這張是**最小可落地**版本（你後面再擴充也不會推倒重來）：

#### Bronze（原始）

1. `brz_cms_ad_play_event`：廣告播放紀錄（何時、哪台、播了什麼）

2. `brz_sensor_observation_event`：感測事件（人流、注視、停留、其他…先都收）

#### Silver（標準化）

1. `slv_ad_exposure`：把「播放」標準化成曝光（exposure）單位，補齊 store/device/time key

2. `slv_person_behavior`：把「感測事件」標準化成 person_key 的行為序列（可彙總到分鐘/曝光窗）

#### Gold（分析資產）

1. `gld_engagement_fact`：把 exposure × 行為對齊，得到 watch/dwell/gaze 之類 KPI

2. `gld_audience_tag_snapshot`：受眾標籤快照（混合欄位：固定 + Map），支援受眾包分析

> 先把「看什麼廣告會停留更久」跑起來；Clean Room / uplift 後面再接到 `gld_*` 的彙總結果。

---

### 1\.5 常用的表屬性（你可以當作團隊的預設模板）

- Bronze：偏 Append 為主、以 `event_date` 分區（partition）

- Silver/Gold：需要 `MERGE` 更新、建議開 `delta.enableChangeDataFeed=true`（若下游要吃增量）

- 可先開 Auto Optimize（寫入小檔合併）讓你們少踩雷

---

# 2\. Delta Table Schema 設計建模（多標籤動態適應）

你現在最大的痛點其實是這句：

> 「行為屬性會隨新感測器增加，要能自動抽象成新 Attribute，不要重構大表」

我建議用 **「Tag 三件套」**，把「標籤定義」「標籤事件」「標籤快照」拆開，才不會每次加標籤就炸表。

---

## 2\.1 Tag 三件套（最穩、最好講清楚）

### (A) `dim_tag_registry`（標籤註冊表：定義層）

用途：**告訴系統「現在有哪些標籤」與其語意、型別、來源、版本**

最少欄位：

- `tag_id`（唯一鍵）

- `tag_name`

- `tag_type`（categorical / numeric / boolean）

- `tag_source`（cms / aicamera / wifi / external_api）

- `description`

- `status`（active/deprecated）

- `version`

- `updated_at`

> 新感測器來了？先新增 registry 記錄，就能「被系統看見」。

---

### (B) `fact_tag_event`（標籤事件表：長尾彈性）

用途：用 **EAV（Entity-Attribute-Value）** 方式存「任意標籤」的值，永遠不用加欄位。

最少欄位：

- `person_key`

- `tag_id`

- `tag_value_str`（類別型）

- `tag_value_num`（數值型，可空）

- `event_ts`（生效時間）

- `cid / store_id / device_id`（建議保留，用於場域分析）

- `data_date`

> 任何新標籤（天氣、活動、WiFi 推估年齡…）都能直接進這張表。

---

### (C) `gld_audience_tag_snapshot`（標籤快照：查詢效率）

用途：給分析師/報表/特徵工程用的「快查版本」，用你第二部分提到的 **Hybrid（固定欄位 + Map）**。

最少欄位（建議）：

- `person_key`

- **固定欄位（常用、要快）**：`time_slot`, `region`, `store_id`, `gender_bucket`…（先挑 10 個以內）

- `custom_tags MAP<STRING, STRING>`（長尾類別標籤）

- `computed_scores MAP<STRING, DOUBLE>`（長尾數值標籤/模型分數）

- `tag_version`

- `snapshot_date`

> 你們加新標籤時：\
> 先進 `fact_tag_event` → 再每天/每週彙整成 `gld_audience_tag_snapshot`。\
> 如果某個 tag 變得很常用，再「升級」成固定欄位即可（不必一開始就猜）。

---

## 2\.2 「受眾包 id_segmentation」怎麼落地（不複雜版）

你可以把受眾包當成「一個可重現的規則組合」，拆成兩張表：

### (A) `dim_segment_definition`

- `segment_id`（穩定 id，可用 hash）

- `segment_name`

- `definition_json`（例如：{time_slot:'rainy_evening', region:'A', gender:'M'}）

- `created_at`, `is_active`

### (B) `fact_segment_membership`（可選，若要固定會員名單）

- `segment_id`

- `person_key`

- `snapshot_date`

**MVP 建議**：先不要固化 membership（會很大），用 `gld_audience_tag_snapshot` + `definition_json` 動態過濾就好。

---

## 2\.3 讓「廣告內容」也走同一套（Content Hub 的對應）

### `dim_ad_asset`

- `ad_id`, `campaign_id`, `brand`, `category`, `duration_s`, `created_at`

### `fact_ad_tag`

- `ad_id`, `tag_id`, `tag_value_str/tag_value_num`, `version`

> 這樣你在做 Content-Audience Fit 時，就是：\
> `gld_engagement_fact` JOIN `gld_audience_tag_snapshot` JOIN `fact_ad_tag`

---

## 2\.4 最小 DDL 範本（你可直接貼到 Databricks SQL 改名就用）

```
-- (1) Tag Registry
CREATE TABLE IF NOT EXISTS dim_tag_registry (
  tag_id STRING,
  tag_name STRING,
  tag_type STRING,
  tag_source STRING,
  description STRING,
  status STRING,
  version INT,
  updated_at TIMESTAMP
) USING DELTA;

-- (2) Tag Event (EAV)
CREATE TABLE IF NOT EXISTS fact_tag_event (
  person_key STRING,
  tag_id STRING,
  tag_value_str STRING,
  tag_value_num DOUBLE,
  cid STRING,
  store_id STRING,
  device_id STRING,
  event_ts TIMESTAMP,
  data_date DATE
) USING DELTA
PARTITIONED BY (data_date);

-- (3) Tag Snapshot (Hybrid)
CREATE TABLE IF NOT EXISTS gld_audience_tag_snapshot (
  person_key STRING,

  -- 核心固定欄位（先少量）
  store_id STRING,
  time_slot STRING,
  region STRING,

  -- 長尾彈性
  custom_tags MAP<STRING, STRING>,
  computed_scores MAP<STRING, DOUBLE>,

  tag_version INT,
  snapshot_date DATE,
  updated_at TIMESTAMP
) USING DELTA
PARTITIONED BY (snapshot_date);

```

---

## 2\.5 你們團隊最常遇到的「動態標籤」決策規則（超好溝通）

- **放固定欄位**：每週都會用來 groupby/filter、而且會進報表 KPI 的（例如 time_slot / store_id / region）

- **放 Map / Tag Event**：長尾、偶爾才用、或還在試驗中的（例如新感測器吐出來的 20 種指標）

- **升級策略**：當某個 tag 的使用率穩定、且查詢成本高 → 從 Map 升為固定欄位（這是「演進」，不是推倒）

---

如果你願意，我可以在你這份文件的「第三部分」下面，再補一頁 **「從 Bronze → Silver → Gold 的資料流」ASCII 架構圖**（一眼能講給主管/合作方聽懂），並把 6 張 MVP 表跟你第一部分的 Audience/Content/Conversion Hub 一一對上。


