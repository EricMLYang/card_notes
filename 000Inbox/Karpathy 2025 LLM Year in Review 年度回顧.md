---
tags:
  - my-article
Checkbox 1: false
---
# Karpathy 2025 LLM Year in Review 年度回顧

https://karpathy.bearblog.dev/year-in-review-2025/?fbclid=IwdGRjcAOzPQljbGNrA7M9A2V4dG4DYWVtAjExAHNydGMGYXBwX2lkDDM1MDY4NTUzMTcyOAABHio7CqP-Tesyj1bYK-\_hQMuLcTKOLgD9FRjfYddoav1Kc66Cf51lX6qLnFAm_aem_FT5zIYUa1bFknGYnHppW9A



大神 Karpathy 發表了他的 2025 LLM Year in Review 年度回顧，整理了今年 LLM 領域最顯著的「典範轉移」，以下是快速摘要翻譯 (原文連結放留言)



🔹 1. RLVR 強化學習成為新標準



2025 年前的 LLM 訓練流程是: 預訓練 → SFT 監督微調 → RLHF 人類回饋強化學習。今年 RLVR (Reinforcement Learning from Verifiable Rewards) 成為新的重要階段。透過在可驗證環境(如數學/程式題目)中訓練，LLM 自發發展出「推理」策略，學會將問題分解成中間步驟。



跟 SFT 和 RLHF 不同，RLVR 是針對客觀(不可被欺騙的)獎勵函數進行訓練，因此可以優化更長時間。由於 RLVR 能提供更高的能力/成本比，原本用於預訓練的算力被轉移過來。因此 2025 年的進展主要來自更長的 RL 訓練，而非更大的模型。這個新階段還帶來一個全新的調控旋鈕: 透過生成更長的推理軌跡、增加「思考時間」，可以用測試時計算量來控制能力(以及對應的 scaling law)。OpenAI o1 是首個 RLVR 模型展示，但 o3 的發布才是真正讓人直覺感受到差異的轉折點。



🔹 2. 幽靈 vs 動物 / 參差不齊的智慧



2025 年讓我(以及整個業界)開始直觀理解 LLM 智慧的「形狀」。我們不是在「演化/培育動物」，而是在「召喚幽靈」。LLM 的一切都不同(神經架構、訓練資料、訓練演算法，尤其是優化壓力)，所以產生的是完全不同的智慧實體，不適合用動物的視角來思考。



人類神經網路為叢林中部落生存而優化，但 LLM 為模仿人類文字、在數學題目中獲得獎勵、在 LM Arena 上獲得讚而優化。由於可驗證領域允許 RLVR，LLM 在這些領域附近的能力會「突刺」起來，整體呈現出有趣的參差表現: 它們同時是天才博學者，又是困惑的小學生，隨時可能被越獄攻擊騙走你的資料。



這也連帶讓我對 benchmark 失去信任。核心問題是 benchmark 幾乎都是可驗證環境，因此立即容易受到 RLVR 或透過合成資料生成等較弱形式的影響。在典型的刷榜過程中，LLM 實驗室的團隊不可避免地會在 benchmark 所佔據的嵌入空間小區域附近建構環境，長出「突刺」來覆蓋它們。「在測試集上訓練」成了一種新的藝術形式。「打爆所有 benchmark 但還是沒達到 AGI」會是什麼樣子？



🔹 3. Cursor / LLM App 新層次



Cursor 今年最值得注意的(除了爆發性成長)是它揭示了「LLM App」的新層次，人們開始談論「X 領域的 Cursor」。正如我今年在 Y Combinator 演講中強調的，像 Cursor 這樣的 LLM App 為特定垂直領域打包和編排 LLM 呼叫:



\- 做「context 工程」

\- 在背後編排多個 LLM 呼叫，串成越來越複雜的 DAG，仔細平衡效能和成本

\- 為人機協作提供應用程式專屬 GUI

\- 提供「自主性滑桿」



2025 年很多討論圍繞這個新 App 層有多「厚」。LLM 實驗室會吃掉所有應用嗎？還是 LLM App 有綠色草原？我個人認為 LLM 實驗室會傾向於培養出能力全面的大學畢業生，但 LLM App 會透過提供私有資料、感測器、執行器和回饋迴路，將他們組織、微調並部署成特定垂直領域的專業人員。



🔹 4. Claude Code / 活在你電腦上的 AI



Claude Code 是第一個令人信服的 LLM Agent 展示，以迴圈方式串連工具使用和推理來進行延伸的問題解決。更重要的是，它運行在你的電腦上，使用你的私有環境、資料和上下文。



我認為 OpenAI 搞錯了方向，他們把早期的 Codex/Agent 努力放在從 ChatGPT 編排的雲端容器部署上，而不是簡單的 localhost。雖然雲端運行的 Agent 群集感覺像是「AGI 終局」，但我們現在處於能力參差、起飛相對緩慢的中間世界，直接在開發者電腦上運行 Agent 更合理。注意，關鍵區別不在於「AI ops」碰巧在哪裡運行(雲端、本地或其他)，而在於其他一切: 已經存在並開機的電腦、其安裝環境、上下文、資料、密鑰、配置，以及低延遲互動。



Anthropic 正確理解了這個優先順序，將 Claude Code 包裝成令人愉悅、極簡的 CLI 形式，改變了 AI 的樣貌: 它不只是你去訪問的網站如 Google，它是「住」在你電腦上的小精靈/幽靈。這是與 AI 互動的全新典範。



🔹 5. Vibe Coding



2025 年是 AI 跨越能力門檻的一年，可以僅透過英文描述來建構各種令人印象深刻的程式，忘記程式碼甚至存在。有趣的是，我在一則隨意的推文中創造了「vibe coding」這個詞，完全沒料到它會傳播這麼遠 :)



有了 vibe coding，程式設計不再嚴格保留給受過高度訓練的專業人員，任何人都可以做。這是我寫的「Power to the people: LLM 如何翻轉技術擴散」的又一個例子: 與以往所有技術形成鮮明對比，普通人從 LLM 獲得的好處遠多於專業人員、企業和政府。



但 vibe coding 不僅賦能普通人接觸程式設計，也讓受過訓練的專業人員能寫出更多否則永遠不會寫的程式。在 nanochat 專案中，我用 vibe coding 寫了自己的高效 BPE tokenizer (用 Rust)，而不需要採用現有函式庫或深入學習 Rust。我今年 vibe coded 了很多專案作為快速 App demo (例如 menugen、llm-council、reader3、HN time capsule)。我甚至 vibe coded 了整個一次性 App 只為了找一個 bug，因為何樂而不為呢？程式突然變得免費、短暫、可塑、用完即丟。Vibe coding 將重塑軟體並改變工作內容。



🔹 6. Nano Banana / LLM GUI



Google Gemini Nano Banana 是 2025 年最令人難以置信、典範轉移的模型之一。在我的世界觀中，LLM 是類似 1970-80 年代電腦的下一個主要運算典範。因此，我們會看到類似的創新出於根本相似的原因。我們會看到個人電腦的對應物、微控制器(認知核心)的對應物、網際網路(Agent 網路)的對應物等等。



特別是在 UI/UX 方面，與 LLM「聊天」有點像 1980 年代對電腦控制台下指令。文字是電腦(和 LLM)偏好的原始資料表示，但不是人們偏好的格式，尤其在輸入端。人們其實不喜歡閱讀文字，它緩慢且費力。相反，人們喜歡視覺化和空間化地消費資訊，這就是為什麼傳統運算發明了 GUI。



同樣地，LLM 應該用我們偏好的格式與我們說話: 圖像、資訊圖表、投影片、白板、動畫/影片、Web App 等。目前的早期版本是 emoji 和 Markdown，用標題、粗體、斜體、清單、表格來「裝飾」和排版文字以便於閱讀。但誰會真正建構 LLM GUI？在這個世界觀中，Nano Banana 是早期的暗示。重要的是，它不只關於圖像生成本身，而是關於文字生成、圖像生成和世界知識的聯合能力，全部糾纏在模型權重中。



🔹 Karpathy 總結



2025 年是 LLM 令人興奮且略感驚訝的一年。LLM 正作為一種新型智慧出現，同時比我預期的聰明得多，也比我預期的笨得多。無論如何，它們極其有用，我認為即使在目前能力下，業界也還沒有實現它們潛力的 10%。同時，有太多想法可以嘗試，概念上這個領域感覺非常開放。正如我今年在 Dwarkesh podcast 中提到的，我同時(表面上看似矛盾地)相信我們會看到快速且持續的進展，但同時還有很多工作要做。繫好安全帶吧。