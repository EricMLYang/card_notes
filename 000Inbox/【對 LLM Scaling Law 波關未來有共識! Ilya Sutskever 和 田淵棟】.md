---
tags:
  - my-article
Checkbox 1: false
---
【對 LLM Scaling Law 波關未來有共識: Ilya Sutskever 和 田淵棟】



最近剛好陸續看到這兩個影片，

同樣都很精采，

我彙整一下針對 LLM Scaling 未來看法，

但我還是要強調我講了一年多的看法，

就算模型已經不進步了，模型現在能力已經足夠我們做很多事，只是模型還是不斷的進步。

—



這兩段訪談確實有驚人的相似之處，顯示出處於AI研究最前沿的頂尖科學家們，對於下一步該往哪走有著高度的共識。

這位中國研究員是田淵棟 (Yuandong Tian)。

先為你簡介這兩位主角，接著針對他們的論點進行比較，並補充關於模型應用面的觀察。

---

人物簡介

Ilya Sutskever：前OpenAI首席科學家，現為SSI (Safe Superintelligence Inc.) 創辦人。深度學習歷史上的傳奇人物，從AlexNet到GPT系列的核心推手。當前目標是跳過商業產品競爭，直接追求安全的超智慧。

田淵棟：前Meta FAIR研究總監兼科學家。長期深耕於強化學習、思維鏈與大模型推理能力的研究。目前處於重新思考AI職涯與下一步的階段，強調研究品味的重要性。

---

高度重疊的論述

兩位科學家不約而同地指出了目前AI發展的瓶頸與轉折點，核心共識如下：

Scaling Law的邊際效益遞減

Ilya提到 Scaling 的時代正在過去，因為數據是有限的，且我們不能只靠把模型放大100倍來解決所有問題。

田淵棟更直白地說Scaling Law指向一個悲觀的未來。因為它要求指數級的資源投入才能換取線性的能力增長，這最終會耗盡地球資源。他認為這條路走不通，必須尋找更高效的算法。

人類與AI的樣本效率差距

Ilya質疑為什麼人類只需要極少的數據就能學會，而模型需要海量數據，這代表目前的學習機制還不夠本質。

田淵棟提到人類與模型在學習所需數據量上有1000倍的差距。人類能從極少樣本中提取深刻的洞察，目前的模型只是在做大量的統計擬合。

解決方案：回到研究與強化學習

Ilya提出Age of Research，強調需要新的範式。重點轉向RL，讓模型透過自我對弈或價值函數來學習，而不只是被動閱讀數據。

田淵棟認為SFT就像聽老師講課，是被動的；而RL就像自己去探索，是主動學習，能主動改變數據分佈，這才是產生真正推理能力與原創性的關鍵。

---

不一樣的視角

雖然大方向一致，但兩人的關注點有所不同：

終極目標方面，Ilya更關注安全超智慧，如何控制一個比人類強大得多的智能，以及其對人類的長期影響。田淵棟更關注方法論與效率，如何改進算法讓模型能像人類科學家一樣思考。

對研究的定義上，Ilya從宏觀層面認為整個產業需要從工程擴展回歸到尋找新配方。田淵棟從執行層面提到，由於基礎模型訓練變得高度標準化，未來的價值在於擁有獨特的研究品味，去做那些大廠沒在做、非共識的探索。

組織觀點上，Ilya主張集中力量，SSI聚集算力與人才，不分心做產品，只為了解決最難的問題。田淵棟認為研究可能會變成游擊戰，不一定依賴大廠，小團隊或個人若有獨特洞察，也能做出重要貢獻。

---

模型應用面的議題

田淵棟在訪談中補充了許多Ilya較少觸及的務實觀點，特別是關於AI如何落地與工程師的未來：

Agent與自動化

AI的應用將從單純的對話，轉向Agent。低階自動化包括回郵件、管理Todo list、自動化繁瑣流程，這部分肯定會發生，且會取代大量重複性勞動。高階自動化方面，AI能否像科學家一樣，進行假設、驗證、發現的過程，如果AI能輔助甚至自動化科學發現，那將是應用層面的聖杯。

垂直領域與通用模型

未來的模型生態會分化。通用模型由少數巨頭壟斷，作為基礎設施。垂直模型方面，田淵棟認為在特定領域如科學發現、特定行業應用，開源模型或小參數專用模型仍有機會。不需要一個模型在所有方面都考100分，只需要在特定任務上極強即可。

對工程師職涯的衝擊

隨著AI編碼能力變強，純粹執行端的工程師需求會減少。未來的應用開發者，不再是寫樣板代碼的人，而是懂得如何定義問題、擁有領域知識，並能指揮AI Agent完成任務的人。

---

總結

這兩支影片其實在講述同一個故事的兩面：深度學習的暴力破解期已經結束。

Ilya站在神壇上，思考的是如何創造出下一個超智慧並確保它不毀滅世界。

田淵棟站在戰壕裡,思考的是在資源有限、Scaling撞牆的情況下，如何用更聰明的算法突圍，以及這對未來的開發者與應用意味著什麼。