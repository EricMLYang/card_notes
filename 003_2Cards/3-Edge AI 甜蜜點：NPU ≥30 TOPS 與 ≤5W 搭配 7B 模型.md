# 3-Edge AI 甜蜜點：NPU ≥30 TOPS / ≤5W 搭配 7B 模型

**類型**：Heuristic

## 概念

端側 AI 的技術甜蜜點已經確立：**NPU ≥ 30 TOPS / ≤ 5W** 是邊緣 LLM 部署的核心規格。為什麼是 30 TOPS？可以流暢運行 7B 參數的量化 LLM、支持實時多模態推理、滿足大部分日常 AI 應用需求。為什麼是 5W？手機/筆電等移動設備的功耗限制、散熱和電池續航考量、成本控制。市場趨勢：雲端 GPU 價格 12 個月內上漲約 14%，推動終端自給自足需求；2037 年端側 AI 將快速增長。7B 模型是端側部署的最佳選擇（Gemma 7B 是目前代表），1年內各家 LLM 差異化縮小，競爭會轉向 inference 效率。技術背景：Transformer 比 CNN 更能看連續全局（自駕仍是 CNN base，所以容易撞大片卡車）；NPU 角度看，莫爾定律沒變。

## 重要性

這是判斷「Edge AI 產品規格」的錨點——30 TOPS / 5W / 7B 是三位一體的設計準則。

## 邊界/反例

複雜推理任務仍需雲端支援；7B 模型的上下文長度有限；特殊領域可能需要更大模型。

## 標籤

#EdgeAI #NPU #7B模型 #端側部署 #功耗
