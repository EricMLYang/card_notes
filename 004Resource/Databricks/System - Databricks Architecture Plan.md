---
tags:
  - vms
  - data-platform
  - databricks
---
# System - Databricks Architecture Plan

- [Databricks on AWS – An Architectural Perspective (part 1)](https://www.bluetab.net/en/databricks-on-aws-an-architectural-perspective-part-1/)

- [Databricks Feature Store 101: A Complete Guide (2024)](https://www.chaosgenius.io/blog/databricks-feature-store/)

## \[ Deep into detail \]

- [Delta Table Design](https://app.heptabase.com/e2b4d180-4e0a-45c6-9989-dea4bc781f8a/card/cbd3ae78-d56f-4761-9676-4f258f73dd9f)

- [Databricks Delta Tables 技巧和概念.md](./Databricks%20Delta%20Tables%20技巧和概念.md)

- [Databricks Delta Table  vs SQL .md](./Databricks%20Delta%20Table%20%20vs%20SQL%20.md)

- [Databricks Computed Plan - Apache Spark](https://app.heptabase.com/e2b4d180-4e0a-45c6-9989-dea4bc781f8a/card/96a80b81-c689-4b37-ac02-57ce3de17b18#0fc4304d-49e9-4cf2-9f2f-b8d442b7a622)

   

## **\[ 綜合規劃 \]**

### **1\. 簡易數據管理機制**

#### **數據進入 Databricks 的流程設計**

- **資料源接入方式：**

   - **AWS IoT Core 或 AWS IoT Greengrass：** 適用於實時接收來自 **CANBox** 的物聯網數據

   - **Amazon Kinesis Data Streams：**適合需要高吞吐量的實時數據流處理。

   - **Amazon S3：**

      - 將數據上傳至 S3，Databricks 使用 Autoloader 自動加載新數據

- **Databricks 整合：**

   - **Databricks Autoloader：** 從 S3 或 Kinesis 自動檢測新文件並增量加載

   - **Delta Live Tables (DLT)**

#### **高效、可靠的數據存儲與清理流程**

- **數據一致性與完整性：**

   - **Delta Lake 的 ACID 特性：**確保數據的一致性和可靠性

      - 支持 Schema Enforcement 和 Schema Evolution，防止不合規數據進入。

   - **Schema Validation：**

      - 在數據寫入時驗證數據結構，確保符合預期的 Schema。

- **資料錯誤檢測機制：**

   - **數據質量檢查：**

      - Delta Lake 的 **Constraint** 功能設置數據完整性約束, 及時發現並處理異常數

   - **數據審計與監控：**建立數據審計日志，記錄數據處理歷史

      - 使用**監控工具**（如 Datadog、CloudWatch）監控數據管道健康狀態

#### **應對 CANBox 數據的異常或丟失**

- **數據完整性檢查：**

   - **缺失值處理：**在數據接收階段檢測缺失值, 根據業務需求進行補插、填充或忽略

   - **異常值檢測：**用統計方法模型識別異常數據點, 標記並隔離異常數據

- **重試與補償機制：**

   - **數據重傳：** 設計可靠的傳輸協議，當數據傳輸失敗時，CANBox 自動重傳數據

   - **緩存機制：**設備端數據緩存，確保網絡中斷時數據不丟失, 恢復後自動上傳緩存數據

---

### **2\. Delta Table Schema 規劃**

#### **Delta Table Schema 設計**

- **統一管理與分表管理的取捨：**

   - **統一管理：**

      - **優點：**方便數據計分析,  減少表數量便於維護。

      - **缺點：**表過於龐大影響查詢性能, 查詢數據時可能需要掃描整張表

   - **分表管理：**

      - **優點：**針對子系統優化結構提高查詢效率 ;  數據隔離更清晰可針對性優化

      - **缺點：**增加維護成本, 聯合查詢，增加複雜度

- **建議策略：**

   - **初期使用統一的 Delta Table，結合適當的分區和索引策略**

   - **針對高頻查詢或特殊需求的子系統，日後可考慮拆出專表**

#### **統一表與專表的欄位結構設計**

- **統一表的欄位設計：**

   - **主鍵：**`vehicle_id`(車輛 ID)、 `timestamp`(時間戳)、`subsystem_type`(子模組類型)

   - **子系統識別欄位：**`data_key`(數據名稱)、`data_value`（數據值）

   - **元數據欄位 (可選)：**`data_quality_flag`（數據質量標記）

- **專表的欄位設計：**

   - 例如 BMS 表包含 `battery_voltage`、`battery_temperature` 等欄位

#### **處理結構化與半結構化數據**

- **結構化數據：**定義嚴格的 Schema，確保數據一致性

- **半結構化數據（如 JSON 字段）：**

   - 使用 Spark 的內建功能解析 JSON，將其展平存儲

   - 重要的 JSON 字段提取並存儲為單獨的列。

#### **時間序列數據的對齊**

- **基於時間戳的對齊邏輯：**基準時間間隔（如秒、分鐘）進行數據聚合

- **多表對齊的數據聚合：**根據**主鍵**  對統一表和專表進行聯合查詢

---

### **3\. Pipeline 管理**

#### **數據處理 Pipeline** 

- **全流程設計：**使用 Autoloader 或 DLT 數據接收

   - **ETL 分類：Extract**、**Transform**、Feature、**Load**

- **可擴展的 Pipeline 設計：**

   - **模塊化設計：**將不同子系統的處理邏輯封裝為獨立模塊

   - **配置驅動：**使用配置文件或參數化方式，適應不同子系統的數據格式

   - **統一框架：**採用統一的開發框架（如 Spark Structured Streaming）

#### **Pipeline 監控與錯誤處理**

- **監控機制：**

   - **指標監控：**監控數據處理的關鍵指標，如吞吐量、延遲、錯誤率

   - **日志管理：**收集並分析 Pipeline 的運行日志

   - **告警系統：**設置閾值，異常發生時自動發送告警通知

- **錯誤處理機制：**

   - **容錯設計：**對可預期的錯誤實現自動重試或跳過機制

   - **數據隔離：**將錯誤數據單獨存放，避免影響正常數據處理

   - **回溯與重放：**支持 Pipeline 的狀態回溯，必要時重新處理歷史數據

---

### **4\. 資料探索、特徵工程與建模機制**

#### **快速進行資料探索**

- **使用 Databricks Notebook：**交互式分析數據，使用 SQL 或 Spark API 進行即時查詢

- **數據可視化：**利用內建的可視化工具，生成圖表，觀察數據分佈和趨勢

- **自動化數據分析工具：**pandas-profiling 或 Databricks 自動探索功能 快速生成數據報告

#### **特徵工程的標準流程**

1. **理解業務與數據：**熟悉各子系統的功能和數據含義

2. **數據清洗：**處理缺失值、異常值，確保數據質量

3. **特徵選擇與創建：**

   - 基本特徵：直接使用原始數據中的重要字段

   - 派生特徵：通過數學運算、統計分析創建新的特徵

   - 特定子系統特徵：根據子系統專業知識創建具有物理意義的特徵

4. **特徵編碼與標準化：**

   - 對類別型數據進行編碼，數值型數據進行標準化

5. **特徵評估：**

   - 使用相關係數、特徵重要性等方法評估特徵的有效性。

#### **建立特徵儲存庫（Feature Store）**

- **必要性：**

   - 避免重複開發相同特徵，節省時間和資源。

   - 確保在線和離線環境使用相同的特徵計算邏輯。

- **實施方式：**

   - 利用 **Databricks Feature Store** 管理特徵的創建、版本控制和共享

   - 為每個特徵添加元數據，方便查詢和使用

---

### **5\. 模型管理機制**

#### **管理傳統機器學習模型**

- **模型生命週期管理：**

   - **訓練與測試：**使用 Notebook 或自動化 Pipeline 執行模型訓練和測試

   - **版本控制：**對模型進行版本化管理，記錄訓練數據、參數、評估指標

   - **部署與更新：**將模型部署至生產環境，定期或根據性能觸發更新

- **工具選擇：Databricks MLflow：**

   - 建議使用 MLflow 進行模型的追蹤、註冊、部署和監控。

#### **模型監控與效能評估機制**

- **在線監控：**

   - **預測結果監控：**實時監控模型的預測結果，檢測異常值或漂移

   - **業務指標監控：**關注與模型相關的關鍵業務指標，確保模型帶來預期價值

- **效能評估：**

   - **定期評估：**設置評估計劃，定期重新評估模型性能

   - **A/B 測試：**在模型更新時，使用 A/B 測試評估新模型的效果

- **自動化機制：**

   - **自動警報：**當模型性能下降超過預設閾值時，自動發出警報

   - **自動重訓練：**結合 Pipeline，自動觸發模型的重訓練和部署

---

### **6\. 數據應用的彈性**

#### **報表與資訊系統的彈性設計**

- **即時查詢 vs. 批量生成：**

   - **即時查詢：**

      - 提供最新的數據，支持即時決策

      - 對系統性能要求高，可能增加成本

   - **批量生成：**

      - 適合定期報表，降低系統負載

      - 無法獲取最新數據，時效性較低

   - **建議：**關鍵指標提供即時查詢，歷史分析採用批量生成

- **提供 API 給第三方應用程式調用：**

   - **方式：**使用 RESTful API 或 GraphQL，設計安全、高效的數據接口

#### **Delta Table 與應用層的接口設計**

- **數據服務層：**

   - **建立中間層服務：**使用 Spark SQL 查詢 Delta Table，通過 API 將結果提供給應用層。

   - **使用 Databricks SQL Endpoint：**為 BI 工具和應用提供即時的 SQL 查詢能力。

- **性能優化：**

   - **快取機制：**對常用查詢結果進行快取，提高響應速度

   - **查詢優化：**優化 SQL 查詢語句，利用索引和分區，提高查詢效率

- **安全性與權限控制：**

   - **數據訪問控制：**實施角色和權限管理，確保數據安全

   - **數據脫敏：**對敏感信息進行脫敏處理，滿足合規要求

---






