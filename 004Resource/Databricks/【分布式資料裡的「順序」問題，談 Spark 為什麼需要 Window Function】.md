【分布式資料裡的「順序」問題，談 Spark 為什麼需要 Window Function】

做資料工程時，

常常會遇到一個很基本但很容易忽略的問題：

當資料散落在很多台電腦上時，

如果我想算「順序」或「前後關係」，該怎麼辦？

Spark 的 Window Function 就是為了解決這個需求，

簡單分享。

—

---

▋**Spark 的本質：資料不在同一台電腦**

Spark 是分布式運算框架，

意思是：

資料會被拆成一片一片、放在不同機器上，

每台機器只看到自己那一片、

沒有全局視野，

這樣才能做到很大的吞吐量。

但問題來了……

很多分析都需要「同一組資料」之間的比較：

．一個人一天來第幾次？

．這次停留比上次多幾秒？

．過去 5 次的平均是多少？

資料明明在不同電腦，卻要知道它們的上下文，

一般 groupBy 做不到，

因為它會把 N 筆資料聚合成 1 筆，

原始紀錄的粒度消失了，更別說保留順序關係。

—

---

▋**什麼情境一定會需要 Window？**

只要你的需求裡出現以下字眼：

- 前一筆 / 下一筆（lag, lead）

- 第幾名、排名（rank）

- 累積值（running total）

- 分組平均但要保留每筆資料（avg over）

- 移動平均（rolling window）

那基本上就是 Window 的領域。

在 AI Camera 與廣告的專案裡，

像「客人第幾次進店」、「廣告觀看的持續時間」、「過去 N 次的平均」，

都是典型的 Window 邏輯。

---

▋**Spark 怎麼解決？一個極簡的 Window 範例**

例如：

想知道「每個人的平均停留秒數，但又要保留所有原始紀錄」。

```
from pyspark.sql.window import Window
from pyspark.sql.functions import avg

window = Window.partitionBy("person_id")

df.withColumn("avg_stay", avg("stay_seconds").over(window))

```

這段程式的效果是：

資料不會被 groupBy 合併，

但每筆資料都知道自己那一組的平均值。

這是 Window 最重要的價值：

做分組計算，但不破壞原始資料結構。

—

---

▋不用術語的白話原理解釋

Spark 做的事情其實不複雜：

1\.先把同一組的資料搬到同一台電腦 （例如同一個人、同一家店）

2\.在那台電腦裡排隊 按時間、按事件順序排好

3\.排好後從頭掃到尾，一路算過去 算平均、算前後差、算累積 都變成單機線性計算

原本看起來像「跨很多台電腦比較資料」的問題，

Spark 透過先搬再算，

把它變成「一台電腦就能獨立完成的小任務」，

這也是為什麼 partition key 選得好不好，

會嚴重影響效能的原因。

—

---

▋靠記憶體緩衝區來建立視野

Spark Window 能建立「視野」，

核心機制是「記憶體緩衝區（State Buffer）」，

傳統運算是「算完即忘」，

而 Window 執行器擁有短期記憶，

它在掃描資料時，

會將歷史數據暫存在記憶體（像放進口袋），

當處理到目前這筆資料時，就

能**「回頭看」口袋裡的舊資料**進行比較，

簡單說：它用消耗記憶體空間為代價，

換取了對「上下文」的認知能力。

—

▋實務上的坑：不是所有情況都快

Window 的邏輯很直覺，

但有幾個常見陷阱：

1\. Shuffle 的成本可能很高

如果資料原本就不是按你需要的 key 分區，

Spark 得先把資料搬來搬去、重新洗牌，

這個過程叫 shuffle，會是主要的效能瓶頸。



2\. 資料傾斜會讓某台電腦變瓶頸

如果某個 person_id 特別多資料（例如測試帳號、爬蟲），

那台電腦就會拖垮整個 job。

這時候得考慮：

．把極端值先過濾掉

．或用 salting 技巧把大 key 拆散



3\. 記憶體不夠會 OOM

如果 partition 內資料太大、Window frame 又設太寬，

單台 executor 可能撐不住。

這時候得調整 partition 數量或縮小 frame 範圍。

---

—

▋詞彙補充：白話與術語的連結

．把同組資料搬到同一台 → partitionBy 觸發的 shuffle

．在那台電腦裡排序 → orderBy (in window spec)

．一路掃過去計算 → WindowExec operator

．前一筆 / 下一筆 → lag / lead

．分組平均但不合併資料 → AVG() OVER(PARTITION BY)

．移動平均 → ROWS BETWEEN ... PRECEDING

．視窗框架 → Window Frame (ROWS / RANGE)

如果不理解 Window，

在分散式資料處理裡就會缺一大塊拼圖：

如何在沒有中央記憶體的世界裡處理「順序、上下文與比較」這些人類直覺但機器不直覺的需求。

---

—

▋小結

Window Function 不是萬能藥，

但當你需要「保留原始資料粒度、又要做分組比較」時，

它是唯一解。

理解它的原理，

就能在設計資料 pipeline 時做出更好的選擇：

．什麼時候該用 Window

．什麼時候該先 groupBy 再 join 回去

．partition key 怎麼選才不會踩到效能地雷

這些判斷，都是從「理解分布式運算的本質」開始的。


