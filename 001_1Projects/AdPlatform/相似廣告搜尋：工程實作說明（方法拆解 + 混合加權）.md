# 相似廣告搜尋：工程實作說明（方法拆解 + 混合加權）

## 0) 問題定義

給定 `target_ad_id`，從廣告庫找出 Top-N「最相似」的廣告，並且能回答：

- **為什麼相似**（可解釋）

- **結果穩不穩**（同一支廣告、同一版資料，結果應該一致）

---

## 1) 我們可用的輸入資料（你們現況最常見）

一支廣告通常會有多種信號（signals），後面每個方法會用到不同 subset：

- **Metadata（硬欄位）**：industry / brand / format / language / duration / campaign…

- **Tags（標籤）**：Smart Tag / 人工標籤（如：幽默、年輕受眾、短影音、促銷）

- **Transcript（字幕/語音轉文字）**：影片講什麼（相對穩）

- **LLM 影像描述（你們要做的）**：由「切圖/抽幀」→ LLM 產生的廣告內容描述（最容易不穩，需要規格化）

> 重點：**embedding 是對「某段文字」做向量化**，而那段文字可以是 transcript、也可以是 tags 拼成的 text、也可以是 LLM 生成的描述；一定要明確定義「文字怎麼來」。

---

# Part A：單一方法（每個方法各自如何找相似）

## 方法 1：規則式相似（Rule-based）

**相似定義**：符合某些欄位完全一致/包含（例如 industry=飲料、format=直式、tone=幽默）

**用途**：

- 作為 **前置過濾（filter）** 最常用

- 也可單獨當 MVP 相似搜尋（資料少、需求簡單）

**最小核心（概念）**

```
# candidates = ads where industry == target.industry and language == target.language

```

---

## 方法 2：Jaccard（標籤重疊度）

**相似定義**：`tags` 的交集 / 聯集 越大越相似\
**輸入**：target.tags + candidate.tags

**用途**：

- 當作 **可解釋的打分項** 很常用

- 特別適合標籤品質還不錯的系統

**最小核心**

```
def jaccard(a, b): return len(a & b) / len(a | b)

```

---

## 方法 3：聚類（Cluster 相似）

**相似定義**：同一群（同 cluster）就算相似\
**輸入**：tag 向量 / text 向量（或 one-hot tags）

**用途**：

- 想建立「廣告類型學」

- 或要做「同類廣告推薦」而不是精準近鄰

**最小核心（概念）**

```
# cluster_id = kmeans.predict(embedding_or_tag_vector)
# similar = ads where cluster_id == target.cluster_id

```

---

## 方法 4：關聯規則（Association / Lift）

**相似定義**：不是直接算相似度，而是找「常一起出現的標籤組合」用來補齊相似條件\
**輸入**：transactions（每支廣告的 tags）

**用途**：

- 做「類型補齊」：target 有 A,B，則候選若有 A,B,C 常同現就加分

- 很適合當 rerank 的加分訊號

**最小核心（概念）**

```
# rules: {A,B} -> {C} with high lift

```

---

## 方法 5：Embedding 相似（Cosine / ANN Search）

這是業界最常用的「主引擎」，但**必須先說清楚 embedding 的文字來源**。

### 5\.1 Text Embedding（文字向量）

**相似定義**：文字向量距離近（cosine 高）\
**文字來源（穩定優先順序）**：

1. **Transcript / 字幕（建議必用）**：同一影片→同一轉錄結果（存起來，不要每次重轉）

2. **原始欄位拼接**：title / slogan / brand / category / key points

3. **LLM 生成描述（你們要做）**：請只做「離線一次」並版本化（下面會講）

**最重要的工程規格：固定格式 text_blob**

```
def build_text_blob(ad):
    return "\n".join([
        f"TITLE: {ad.get('title','')}",
        f"SLOGAN: {ad.get('slogan','')}",
        f"BRAND: {ad.get('brand','')}",
        f"CATEGORY: {ad.get('category','')}",
        f"TRANSCRIPT: {ad.get('transcript','')}",
        f"TAGS: {', '.join(ad.get('tags', []))}",
    ]).strip()

```

> embedding 模型只吃「文字」，所以**穩定性=文字生成是否 deterministic**。

---

### 5\.2 Tag Embedding（標籤向量）

**相似定義**：標籤語意接近（例如「幽默」跟「搞笑」不一定要完全相同）\
**輸入**：tags → tag embeddings → 平均/加權平均成 ad vector

**用途**：

- 標籤很強時可當主引擎

- 或當 text embedding 的補強訊號

**最小核心（概念）**

```
# ad_vec_tag = mean(tag_vec[t] for t in tags)

```

---

# Part B：你們要做的 LLM「影像切圖 → 廣告描述」：如何做得穩

你擔心「LLM 產生描述不穩」完全合理。業界穩定做法是：

## 原則 1：LLM 只做「離線一次產生 canonical 描述」，不要查詢時即時生成

- **Ingestion / nightly job**：產描述、存 DB、打版本

- 查詢只讀 DB，不重跑 LLM

## 原則 2：LLM 不要輸出自由作文，改輸出「固定 schema 的 JSON」

因為自由作文最容易飄；固定欄位更容易穩，也方便組合成 text_blob。

### 建議的 `ad_card` schema（例）

```
{
  "product": "運動鞋",
  "brand": "X",
  "audience": ["年輕", "跑者"],
  "tone": ["熱血", "幽默"],
  "scene": ["街頭奔跑", "健身房"],
  "key_claims": ["輕量", "耐磨", "折扣15%"],
  "cta": "立即購買",
  "on_screen_text": ["折扣15%", "新品上市"],
  "visual_objects": ["鞋", "跑步", "汗水特寫"]
}

```

## 原則 3：切圖/抽幀流程要 deterministic（固定規則）

例如（你們可用最簡版）：

- 固定抽幀：每 1 秒取 1 張（或 scene-change 抽代表幀）

- 固定切圖：產品主體區、文字區（可先簡單用固定 ROI 或現有 Smart Tag/偵測框）

- OCR 先抽 on-screen text（再交給 LLM 統整）

## 原則 4：把 JSON 轉成「固定順序的描述文字」再做 embedding

LLM 產 JSON → 你們用 deterministic 程式把 JSON 合成文字（避免 LLM 每次寫作風格不同）

```
def ad_card_to_text(card):
    return "\n".join([
        f"PRODUCT: {card.get('product','')}",
        f"BRAND: {card.get('brand','')}",
        f"AUDIENCE: {', '.join(card.get('audience', []))}",
        f"TONE: {', '.join(card.get('tone', []))}",
        f"SCENE: {', '.join(card.get('scene', []))}",
        f"CLAIMS: {', '.join(card.get('key_claims', []))}",
        f"CTA: {card.get('cta','')}",
        f"ON_SCREEN_TEXT: {', '.join(card.get('on_screen_text', []))}",
        f"OBJECTS: {', '.join(card.get('visual_objects', []))}",
    ]).strip()

```

> **Embedding 吃的是這段 deterministic text**，所以穩定性會大幅提升。

---

# Part C：混合式（業界最常用）：Filter + Recall + Rerank（權重加權）

單一方法很少單獨上線。最常用是「兩階段 + 多訊號加權」。

## Stage 0：硬過濾 Filter（避免離譜）

- industry / language / format / brand（視需求）

- time window（例如只比近 12 個月）

## Stage 1：Recall（快速找候選 Top-K）

常用 2 路召回（Hybrid）：

1. **text_embedding ANN** → TopK1（例如 200）

2. **tag_embedding ANN 或 keyword/BM25** → TopK2（例如 200）\
   合併去重 → 候選集合 `C`（例如 300\~500）

## Stage 2：Rerank（多訊號加權排序 Top-N）

對每個候選 `c in C`，計算以下分數：

- `S_text = cosine(emb_text[target], emb_text[c])`

- `S_tag = cosine(emb_tag[target], emb_tag[c])`

- `S_jac = jaccard(tags[target], tags[c])`

- `S_meta = metadata_match_score(target, c)`（industry/format/language…）

- `S_perf = performance_similarity`（可選：效果層級相近才加分）

### 最常見 FinalScore（線性加權，容易落地 + 可解釋）

```
Final = w1*S_text + w2*S_tag + w3*S_jac + w4*S_meta + w5*S_perf

```

### 權重建議起手式（你們這案子很適合）

- **Balanced（一般）**

   - w1(text)=0.50（字幕/描述語意主力）

   - w2(tag)=0.25（類型穩定）

   - w3(jaccard)=0.15（可解釋）

   - w4(meta)=0.10（保底）

- **Strict（展示成熟、不想亂推）**

   - 提高 meta、jaccard，降低 explore

- **Explore（找靈感/找跨類相似）**

   - 提高 text，降低 meta（但仍保留 language/format 保護）

> 權重不是拍腦袋：上線後可以用「人工標註相似對」或「使用者點選/採用」做簡單調參，但第一版先用上面即可。

---

# Part D：工程輸出要求（避免誤會 + 方便除錯）

## 1) 儲存欄位（建議）

- `emb_text_base`：由 title+slogan+transcript+tags 拼成（穩定）

- `ad_card_json`：LLM 產出的固定 schema（版本化）

- `emb_text_ad_card`：由 ad_card_to_text(card) 生成（穩定）

- `emb_tag`：tags 聚合向量（可選）

## 2) 查詢回傳務必帶 explain signals（讓 BU/SI 看得懂）

每一筆相似結果回：

- `final_score`

- `S_text, S_tag, S_jac, S_meta`

- `why_similar`：例如「同產業、同受眾tag、字幕提到相同訴求、同促銷詞」

---

## 一句話收斂（你可以直接貼給工程師）

- **embedding 本身是穩的**，會飄的是「文字怎麼產生」。

- 你們要用 LLM 產影像描述沒問題，但要：**離線一次、輸出固定 JSON、 deterministic 轉文字、版本化保存**。

- 上線最常用架構：**Filter → Hybrid Recall（text/tag）→ Rerank（加權：text+tag+jaccard+meta）**，並回傳可解釋訊號。

---

如果你希望我再更「工程規格化」一點，我可以把這份補成：

- `ad_card` 的正式 JSON Schema（含欄位型別/必填/枚舉）

- 向量版本策略（model_version / prompt_version / frame_sampling_version）

- API spec（request/response）+ 範例 payload（你們內部 demo 可直接用）