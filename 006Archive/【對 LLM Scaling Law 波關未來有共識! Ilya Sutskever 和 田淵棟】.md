---
tags:
  - my-article
Checkbox 1: false
---
【對 LLM Scaling Law 波關未來有共識: Ilya Sutskever 和 田淵棟】



最近剛好陸續看到這兩個影片，

同樣都很精采，

我彙整一下針對 LLM Scaling 未來看法，

但我還是要強調我講了一年多的看法，

就算模型已經不進步了，模型現在能力已經足夠我們做很多事，只是模型還是不斷的進步。

—



這兩段訪談確實有驚人的相似之處，顯示出處於AI研究最前沿的頂尖科學家們，對於下一步該往哪走有著高度的共識。

這位中國研究員是田淵棟 (Yuandong Tian)。

先為你簡介這兩位主角，接著針對他們的論點進行比較，並補充關於模型應用面的觀察。

---

人物簡介

Ilya Sutskever：前OpenAI首席科學家，現為SSI (Safe Superintelligence Inc.) 創辦人。深度學習歷史上的傳奇人物，從AlexNet到GPT系列的核心推手。當前目標是跳過商業產品競爭，直接追求安全的超智慧。

田淵棟：前Meta FAIR研究總監兼科學家。長期深耕於強化學習、思維鏈與大模型推理能力的研究。目前處於重新思考AI職涯與下一步的階段，強調研究品味的重要性。

---

高度重疊的論述

兩位科學家不約而同地指出了目前AI發展的瓶頸與轉折點，核心共識如下：

Scaling Law的邊際效益遞減

Ilya提到 Scaling 的時代正在過去，因為數據是有限的，且我們不能只靠把模型放大100倍來解決所有問題。

田淵棟更直白地說Scaling Law指向一個悲觀的未來。因為它要求指數級的資源投入才能換取線性的能力增長，這最終會耗盡地球資源。他認為這條路走不通，必須尋找更高效的算法。

人類與AI的樣本效率差距

Ilya質疑為什麼人類只需要極少的數據就能學會，而模型需要海量數據，這代表目前的學習機制還不夠本質。

田淵棟提到人類與模型在學習所需數據量上有1000倍的差距。人類能從極少樣本中提取深刻的洞察，目前的模型只是在做大量的統計擬合。

解決方案：回到研究與強化學習

Ilya提出Age of Research，強調需要新的範式。重點轉向RL，讓模型透過自我對弈或價值函數來學習，而不只是被動閱讀數據。

田淵棟認為SFT就像聽老師講課，是被動的；而RL就像自己去探索，是主動學習，能主動改變數據分佈，這才是產生真正推理能力與原創性的關鍵。

---

不一樣的視角

雖然大方向一致，但兩人的關注點有所不同：

終極目標方面，Ilya更關注安全超智慧，如何控制一個比人類強大得多的智能，以及其對人類的長期影響。田淵棟更關注方法論與效率，如何改進算法讓模型能像人類科學家一樣思考。

對研究的定義上，Ilya從宏觀層面認為整個產業需要從工程擴展回歸到尋找新配方。田淵棟從執行層面提到，由於基礎模型訓練變得高度標準化，未來的價值在於擁有獨特的研究品味，去做那些大廠沒在做、非共識的探索。

組織觀點上，Ilya主張集中力量，SSI聚集算力與人才，不分心做產品，只為了解決最難的問題。田淵棟認為研究可能會變成游擊戰，不一定依賴大廠，小團隊或個人若有獨特洞察，也能做出重要貢獻。

---

模型應用面的議題

田淵棟在訪談中補充了許多Ilya較少觸及的務實觀點，特別是關於AI如何落地與工程師的未來：

Agent與自動化

AI的應用將從單純的對話，轉向Agent。低階自動化包括回郵件、管理Todo list、自動化繁瑣流程，這部分肯定會發生，且會取代大量重複性勞動。高階自動化方面，AI能否像科學家一樣，進行假設、驗證、發現的過程，如果AI能輔助甚至自動化科學發現，那將是應用層面的聖杯。

垂直領域與通用模型

未來的模型生態會分化。通用模型由少數巨頭壟斷，作為基礎設施。垂直模型方面，田淵棟認為在特定領域如科學發現、特定行業應用，開源模型或小參數專用模型仍有機會。不需要一個模型在所有方面都考100分，只需要在特定任務上極強即可。

對工程師職涯的衝擊

隨著AI編碼能力變強，純粹執行端的工程師需求會減少。未來的應用開發者，不再是寫樣板代碼的人，而是懂得如何定義問題、擁有領域知識，並能指揮AI Agent完成任務的人。

---

總結

這兩支影片其實在講述同一個故事的兩面：深度學習的暴力破解期已經結束。

Ilya站在神壇上，思考的是如何創造出下一個超智慧並確保它不毀滅世界。

田淵棟站在戰壕裡,思考的是在資源有限、Scaling撞牆的情況下，如何用更聰明的算法突圍，以及這對未來的開發者與應用意味著什麼。

---

## 卡片拆解結果

### A. 主脈絡（論證骨架）

- **核心命題**：Scaling Law（靠放大模型規模提升能力）已接近極限，指數級資源換線性增長的模式不可持續
- **關鍵瓶頸**：人類與AI的樣本效率差距達1000倍，現有學習機制只是統計擬合而非真正理解
- **解法共識**：轉向強化學習（RL），讓模型主動探索而非被動消化數據，才能產生真正推理與創造力
- **產業轉折**：從工程擴展時代（Scaling）進入研究新範式時代（Age of Research），價值回歸到獨特洞察與演算法突破
- **應用分化**：通用模型由巨頭壟斷作為基礎設施，垂直領域專用模型與Agent應用成為新戰場

---

### B. 卡片（Zettel）

#### 序號 1
- **標題**：Scaling Law 的資源詛咒：指數投入換線性回報
- **類型**：Warning
- **概念**：Scaling Law 指向悲觀未來，因為它要求指數級資源投入（數據、算力、能源）才能換取線性的能力增長。這條路最終會耗盡地球資源。兩位頂尖科學家（Ilya 與田淵棟）同時指出，數據是有限的，把模型放大100倍不能解決所有問題。邊際效益遞減意味著必須尋找更高效的算法路徑。
- **重要性**：這是判斷 AI 投資與技術路線的關鍵框架。幫助識別「暴力擴展」與「智慧優化」的分界線。
- **邊界/反例**：Scaling 在達到某些能力閾值前仍有效（如 GPT-3 到 GPT-4 的跨越）；但在逼近資源極限時必須轉向新範式。
- **可連結關鍵詞**：#ScalingLaw #資源效率 #邊際效益遞減 #演算法突破 #第一性原理

---

#### 序號 2
- **標題**：人類 vs AI 的樣本效率鴻溝（1000倍差距）
- **類型**：Model
- **概念**：人類只需極少數據就能學會（從幾個案例提取深刻洞察），而現有 LLM 需要海量數據才能達到相似能力，差距約1000倍。這揭示目前的學習機制本質是「統計擬合」而非「真正理解」。人類擅長從極少樣本中建構因果模型與抽象概念，AI 目前只是在模式匹配。
- **重要性**：這是評估 AI 系統「智慧深度」的核心指標，也是下一代演算法必須突破的方向。
- **邊界/反例**：在特定任務（如圍棋）上，AI 透過強化學習已能超越人類樣本效率；但在通用推理與概念遷移上仍有巨大鴻溝。
- **可連結關鍵詞**：#樣本效率 #學習機制 #因果推理 #概念抽象 #統計擬合

---

#### 序號 3
- **標題**：SFT vs RL：被動聽講 vs 主動探索的學習模式差異
- **類型**：Principle
- **概念**：監督式微調（SFT）如同聽老師講課，是被動接收固定分佈的數據；強化學習（RL）如同自己探索實驗，能主動改變數據分佈、試錯修正。RL 是產生真正推理能力與原創性的關鍵，因為它讓模型透過價值函數或自我對弈來學習「什麼是好的」，而不只是模仿「什麼被展示過」。
- **重要性**：這是理解為何 o1、o3 等新模型能突破的核心機制，也是未來模型訓練範式的分水嶺。
- **邊界/反例**：RL 需要良好的獎勵函數設計，否則會陷入局部最優或產生不符人類價值的行為；在低風險任務上 SFT 仍更高效。
- **可連結關鍵詞**：#強化學習 #主動學習 #數據分佈 #推理能力 #價值函數

---

#### 序號 4
- **標題**：Age of Research：從工程擴展回歸研究新範式
- **類型**：Heuristic
- **概念**：AI 發展已從「工程擴展時代」（靠算力與數據暴力突破）轉向「研究新範式時代」（尋找更本質的學習機制）。未來的價值在於擁有「獨特的研究品味」——去做那些大廠沒在做、非共識的探索。基礎模型訓練變得高度標準化後，差異化來自於對問題本質的獨特洞察。
- **重要性**：這是個人職涯與團隊策略的關鍵轉折點，幫助判斷「跟隨主流」vs「開創新路」的時機。
- **邊界/反例**：獨特研究品味需要長期積累與風險承擔；小團隊若缺乏足夠算力驗證，也可能陷入無法落地的困境。
- **可連結關鍵詞**：#研究品味 #非共識探索 #第一性原理 #差異化競爭 #範式轉移

---

#### 序號 5
- **標題**：通用模型 vs 垂直專用模型的生態分化
- **類型**：Model
- **概念**：未來 AI 生態會分化為兩層：通用模型由少數巨頭壟斷（OpenAI、Anthropic 等），作為基礎設施；垂直領域專用模型（科學發現、特定行業應用）由開源或小參數模型佔據，不需要在所有方面都考100分，只需要在特定任務上極強即可。這是「通用能力」vs「專精效率」的權衡。
- **重要性**：這是理解 AI 商業化路徑與開發者機會的關鍵框架，幫助判斷「做基礎設施」vs「做垂直應用」的策略選擇。
- **邊界/反例**：通用模型的能力邊界仍在擴張，可能吞噬部分垂直領域；但監管、數據隱私、成本考量會保護垂直模型的生存空間。
- **可連結關鍵詞**：#生態分化 #垂直領域 #開源模型 #基礎設施 #專精效率

---

#### 序號 6
- **標題**：AI Agent：從單次對話到自主任務執行的應用跨越
- **類型**：Heuristic
- **概念**：AI 應用將從單純對話工具演化為 Agent（自主代理）。低階自動化包括回郵件、管理 Todo、自動化繁瑣流程；高階自動化是讓 AI 能像科學家一樣進行「假設→驗證→發現」的循環。Agent 的核心特徵是能持續執行多步驟任務、調用工具、自我修正，而不只是回答單一問題。
- **重要性**：這是理解 AI 產品形態演化的關鍵，幫助判斷「對話介面」vs「自主執行」的應用價值差異。
- **邊界/反例**：高階自動化（如科學發現）仍需人類定義問題與驗證結果；低階自動化可能因缺乏情境理解而產生錯誤。
- **可連結關鍵詞**：#AIAgent #自動化層級 #多步驟任務 #科學發現 #工具調用

---

#### 序號 7
- **標題**：AI 時代工程師的價值轉移：從寫代碼到定義問題
- **類型**：Warning
- **概念**：隨著 AI 編碼能力變強，純粹執行端的工程師（寫樣板代碼）需求會減少。未來應用開發者的價值在於：1) 定義問題的能力（什麼才是真正要解決的）；2) 領域知識（理解業務邏輯與限制）；3) 指揮 AI Agent 的能力（把高層意圖轉化為可執行的任務鏈）。技術實現被下推，問題定義與系統設計被上提。
- **重要性**：這是個人職涯重定位的關鍵框架，幫助判斷「應該深化什麼能力」才能在 AI 時代保持價值。
- **邊界/反例**：底層系統工程（如性能優化、基礎設施）仍需深度技術能力；但應用層開發確實正在去技術化。
- **可連結關鍵詞**：#職涯轉型 #問題定義 #領域知識 #系統設計 #槓桿思維

---

### C. 連結建議（組裝藍圖）

**核心論證鏈**：
- **技術瓶頸**：序號1 (Scaling Law 資源詛咒) + 序號2 (樣本效率鴻溝) → 揭示現有路徑不可持續
- **解法路徑**：序號3 (SFT vs RL) + 序號4 (Age of Research) → 指向新範式的方向
- **產業影響**：序號5 (生態分化) + 序號6 (AI Agent) → 描繪應用層變化
- **個人策略**：序號7 (工程師價值轉移) ← 連結回使用者的核心關注（槓桿型系統建造者職涯）

**可與既有卡片連結**：
- 序號7 與 `1-AI 時代應該轉變成槓桿思維.md`、`2-成為認知樂團指揮家，駕馭更高價值任務.md` 形成策略三角
- 序號3 與 `3-模型能力躍升開啟新產品賽道（但也毀滅舊玩家）.md` 說明為何新模型能突破
- 序號5 與 `3-API 思維轉 Agent 思維.md` 共同描繪 AI 產品形態演化