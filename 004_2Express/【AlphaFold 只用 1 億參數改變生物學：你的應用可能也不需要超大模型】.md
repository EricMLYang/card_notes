---
tags:
  - my-article
Checkbox 1: true
---
【AlphaFold 只用 1 億參數改變生物學：你的應用可能也不需要超大模型】

最近同溫層又被 Google Deep Mind AlphaFold 紀錄片洗版，

但讓我驚訝的是 AlphaFold2 模型參數頂多 1億，

根據 **Fox Hsiao** 彙整某文章貼文 (連結放留言），

「五年內，AlphaFold 將人類已知的蛋白質結構數據庫，從 18 萬暴增至 2.4 億。這涵蓋了人體產生的每一種蛋白質，以及新冠病毒、瘧疾等關鍵病原體的結構」

「現在，全球超過 330 萬名研究人員使用 AlphaFold，它如同顯微鏡與移液器，成為生物學家的標準配備。對於新一代的分子生物學研究生而言，學習操作 AlphaFold 就如同學習英語一樣基礎。」

這讓我反思是否要更積極去理解中小模型的垂直領域應用，

先說我自己答案是：是該去積極了解了!

—

以下是彙整 Geminic 和 ChatGPT Deep Seaearch，\
並請 Claude 做一次查證後的簡易整理，

（不要預設 LLM 100％ 對應該是國民素養了吧？）



▋ 為什麼多數企業不該一開始就自建 LLM

只有在遇到明確痛點時，垂直自建才有意義。

第一種情況是數據隱私。

醫療記錄、法律合約、工廠製程參數這類資料，絕對不能離開內網。 



第二種是格式穩定性。 

當你的業務流程需要 100% 穩定的 JSON 或 SQL 輸出時，通用模型會偶發格式錯誤。 

透過微調讓模型「過擬合」於特定格式，能徹底解決這個問題。



第三種是高頻次應用。

產線邊緣運算、即時客服路由，這類場景每天可能呼叫上百萬次。

 7B-8B 模型在單張顯卡上就能達到極高吞吐量，且沒有 API 網路延遲。



最後一種是獨特領域知識。 

你們工廠的機台代號、內部的行政術語，通用模型根本不認識。 透過 RAG 加上微調，可以讓模型「內化」企業語言。

---

▋ 技術門檻沒你想的高

很多人聽到「自建模型」就覺得要燒大錢。 

實際上，2024 年的工具鏈已經把門檻壓到消費級水準。

模型選擇上，7B 到 14B 參數量是甜蜜點。 

中文首選 Qwen 2.5，這是目前開源界中文能力最強的模型。 

英文和代碼選 Llama 3.1 8B，生態系最成熟。 

需要處理長文本就用 Mistral NeMo 12B。

訓練技術的核心是 QLoRA。 

這個技術不重新訓練整個模型，只訓練一小部分參數。 

顯存需求大幅降低，單張消費級顯卡就能搞定。

工具推薦 Unsloth。 

訓練速度快兩倍，顯存節省 60%，而且跟 Hugging Face 生態系完全相容。

推論部署用 vLLM。

這是生產環境首選，利用 PagedAttention 技術大幅提升並發能力。 

如果是邊緣設備或開發階段，Ollama 也很好用。

整套技術棧都是開源的，沒有廠商鎖定風險。

—

---

▋ 費用比你想像的低很多

租用雲端 GPU ，Lambda Labs 或 RunPod 都可以。 

H100 現在大約 $2-3 美元一小時。 

用 Unsloth 加上 QLoRA，微調一個 8B 模型通常只需 2 到 10 小時。

算力成本可能就兩三千台幣。

真正的成本在數據工程。 

清洗數據、構建評測集，這些人力和工具才是重點。 

但這筆投資是必要的，數據品質直接決定模型效果。

後續更新也很便宜。 

每月更新一次產品知識或法規，算力成本幾乎可以忽略。 

流程自動化後，人工介入極低。

部署成本有兩個選項。

如果是高頻穩定應用，建議地端自建。 

配備 2 張 RTX 4090 的工作站，現在大約 20 到 30 萬台幣。 

攤提三年，每月不到一萬。 電費再加兩三千。

如果需要彈性，就租雲端。 

RunPod 的 RTX 4090 實例，一個月約 8,000 台幣。 

租 A6000 Ada 也才兩萬五左右。

完全符合中小企業預算。

—

---

▋ 真實場景

智慧製造的案例很經典。

某工廠每天產生數萬條機台 Error Log。 

代碼難懂，資深師傅的經驗又難以傳承。 而且數據不能上公有雲。

他們收集過去三年的維修紀錄和手冊。 

用 Qwen 2.5 7B 做 QLoRA 微調。 

讓模型學會「Error Code A01 = 檢查皮帶張力」這類知識。

部署在產線工控機上，配一張 RTX 4090。 

新手操作員輸入錯誤代碼，AI 直接給出標準排查步驟。 無延遲，無隱私外洩。

法律合規也有需求。



小型法務團隊要審閱大量供應商合約。 

重點是抓出不合規的賠償條款，不需要通用聊天。

他們用 RAG 檢索標準法規，再微調 Llama 3。 

微調重點在輸出格式控制。

 要求模型輸出 JSON，包含風險等級、

違規條款原文、建議修改意見。

審閱時間從三天縮短到 30 分鐘。 

格式統一，直接匯入 ERP 系統。

電商的需求更直接。



上百家供應商的產品規格書，PDF 和 Excel 格式都不一樣。 

需要整理進資料庫。

他們不追求對話，只追求提取。 

訓練 Mistral 7B 專門做「Text to JSON」。

成本比用 GPT-4 API 節省 90% 以上。 

提取準確率因微調而提升。

—

---

▋ 行動建議

如果你正在評估 AI 導入方案，

記住一個原則：買卡不如租卡訓練，

地端推論優於雲端 API。

先以 Unsloth 加上 Llama 3.1 8B 或 Qwen 2.5，

在雲端租賃 GPU 進行一次 POC。 

驗證數據清洗的效果，這才是成敗關鍵。

別被「自建模型」的名詞嚇到。 

技術門檻已經降到中小企業可負擔的水準。

重點不在模型有多聰明。 

重點在於它能不能穩定、精確地解決你的特定問題。







<https://www.facebook.com/share/p/1G4ccGZ5tp/>