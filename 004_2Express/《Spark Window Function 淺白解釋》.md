《Spark Window Function 淺白解釋》

▋ 什麼時候會用到 Window Function

當你處理的問題不只是「這一列」的事，

而是需要同時參考「前後其他列」時，

Window 就派上用場了。

.

.

最常見的場景包括:

．移動平均(需要看前面幾列)、

．累積和 Running Sum(需要看前面所有列)、

．排名 Rank、Dense Rank、Row Number(需要知道鄰近列的順序)。

．某個範圍內的統計值，例如計算落在時間 X 分鐘內的加總。

.

.

只要你的運算需要「看左右鄰居」、

「看自己在群組裡的位置」、「看前後資料」，

就必須使用 Window。 這是 Window 存在的核心理由。

—

．

▋ 一般運算的侷限性

一般的 SELECT 計算只能用「該列本身的值」去算結果，

 比如 price \* 0.8 這種單列運算。

groupBy 雖然可以跨列運算，

但它的缺點是會把資料壓縮成一列，

所有原始細明記錄都消失了，

因此無法做到「每一列都能看到其他列」的效果。

Window 的特點剛好介於兩者之間，

 它保留所有原始列，

但每一列在計算時可以看見自己的「上下文」。 



▋ Window 的三個核心設定

Window 的本質其實就一件事:

定義「每一列能看到哪些其他列」，

Spark 或 SQL 用三個設定把這件事講清楚，

.

.

第一個設定是 PARTITION BY，用來定義分組邊界，

意思是「某一列在看其他列時，只能看同一組裡的列」。

例如按照 user_id 分組，

那 user A 的資料只會看到 user A。

這讓不同群組之間互不干擾。

.

.

第二個設定是 ORDER BY，

用來定義一組資料裡的順序，

例如按照時間排序，

Spark 才能知道「這一列前面是誰、後面是誰」。 

沒有 ORDER BY，就無法定義 running sum、移動平均、排名這些與順序相關的運算。

.

.

第三個設定是 ROWS 或 RANGE，

用來定義「可見範圍」。 

舉例來說，ROWS BETWEEN 3 PRECEDING AND CURRENT ROW 

表示一列在運算時可以看到「前 3 列加上自己」。



這正是移動平均、滑動窗口能成立的核心，

RANGE 則是依據排序欄位的值,例如「前 10 分鐘內的資料」。

—

.

.

▋ 為什麼這三件事就能做到 Window

Window 的核心問題只有一個:

「這一列在運算時，哪些列算是它的鄰居?」

PARTITION BY 決定「同一村」。 

ORDER BY 決定「住戶門牌順序」。

 ROWS 或 RANGE 決定

「要看左邊三戶?或看附近 10 分鐘內所有人?」



定義完這三件事，

就能準確指出「這一列要看哪些列」，

 而任何需要前後文的運算，像是移動平均、running sum、排名等，

就都能在這樣的定義下完成。

—

.

.

▋ Spark Window 的實際運行流程

整個 Window 的底層流程可以用最簡單的方式理解，

第一步是依 PARTITION BY 做 shuffle，

Spark 把同一組(例如 user_id 一樣)的資料搬到同一個 Executor 的 partition 裡，

這樣同一組資料才能一起處理。

.

第二步是在每個 partition 裡依 ORDER BY 排序。

 排序讓 Spark 知道「前後關係」，

 沒有排序,就無從算累積、移動平均或排名。

.

第三步是對排序好的資料進行逐列計算，

Spark 會把 Window 變成一段 Java 迴圈， 

這個迴圈每次處理一列，

並同時保留需要的「視窗狀態」，

例如 running sum 就是累加器，

移動平均就是一個 3 或 7 天的 buffer，

排名則是比較前一列的值來決定 rank 要不要加 1。

.

第四步是每一列都會輸出。

 不同於 groupBy 會壓縮資料，

Window 會輸出跟原資料一樣多的列。

 並多出 Window 的結果欄位。

—

Window 的本質就是「定義每一列能看到哪些其他列」，

 透過 PARTITION BY、ORDER BY、ROWS/RANGE 三個設定，

就能精準控制這件事，

 Spark 則是用 shuffle、排序、逐列計算的流程來實現，

理解這個邏輯，比較能靈活運用 Window 處理各種前後文相關的分析需求。


