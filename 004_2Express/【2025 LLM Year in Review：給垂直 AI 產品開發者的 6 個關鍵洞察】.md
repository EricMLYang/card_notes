---
tags:
  - my-article
Checkbox 1: true
---
【2025 LLM Year in Review：給垂直 AI 產品開發者的 6 個關鍵洞察】

看到 張文鈿分享 Karpathy 的年度回顧，

根據 內容，

我將從「做垂直 AI 產品」的視角，

重新解讀 2025 年 LLM 領域的重要發展。

---

---

▋ 推理成本成為新的設計變數

2025 年，LLM 訓練流程加入了新階段：

強化學習驗證獎勵（RLVR）。 

模型在可驗證環境中，

像是數學題、程式碼謎題，透過客觀獎勵函數進行長時間優化。 

它們自發發展出「推理」策略。 

會把問題拆解成中間計算步驟，會來回嘗試不同解題方法。

OpenAI o1 在 2024 年底首次展示這個能力。 

但 o3 在 2025 年初發布時，能直覺感受到那個拐點。 

最重要的是，這帶來一個全新的控制旋鈕：test-time compute，也就是思考時間。

真正能控制的是推理預算分配。

 每個任務步驟要花多少「思考成本」換取多高成功率。 

這是一個三角困境：延遲、費用、成功率，必須精準權衡。



垂直產品的競爭力落在：

把「長推理」用在刀口上。 哪些步驟需要深度思考？

像是關鍵決策、複雜驗證。 

哪些用便宜模型、規則引擎或快取就夠？

像是格式轉換、簡單分類。



關鍵問題：任務鏈中，哪些子步驟是「可驗證」的？ 

如果只能控制 test-time compute，

該把「長思考」放在哪 10% 最划算？ 什麼情況下「更長推理」反而有害？



推理成本不再是黑盒，而是戰術槓桿。

---





▋ 模型升級會打爆產品

Karpathy 用了一個比喻：

我們在「召喚幽靈」，不是「養動物」。 

LLM 的智能形狀跟人類完全不同。

人類神經網路被優化來在叢林中存活。

 LLM 神經網路被優化來模仿人類文字、在數學謎題中獲得獎勵、

在 LM Arena 上得到人類按讚。

因為可驗證領域允許 RLVR，LLM 在這些領域的能力會「尖刺化」。

 它們同時是天才博學者，也是困惑的小學生。

 幾秒鐘後就可能被越獄騙走資料。



2025 年，整個產業開始直覺理解這種「尖刺智能」的形狀。

 Karpathy 對 benchmark 失去了信任。

 因為 benchmark 幾乎天生就是可驗證環境，

立刻就會被 RLVR 和合成資料針對性優化。

模型升級等於產品改版。



新模型常常會破壞原本的 prompt 框架和行為模式。 

護城河會是完整的評測體系、回歸測試集。 

是監控模型行為變化的可觀測性。 

是持續對抗越獄和資料外洩的紅隊與風控機制。



關鍵問題：如何建立「模型回歸測試集」，

至少包含哪 5 類失敗案例？ 

需要哪些 online 指標來判斷「框架加模型」在真實任務的成功？ 

最容易被忽略的越獄路徑是什麼，

尤其在 tool use 和 agent 場景？



模型會升級，防禦機制也要跟著進化。

---

▋ LLM App 是編排層

Cursor 在 2025 年的崛起揭示了 LLM App 的新層次。 

人們開始說「Cursor for X」。

Cursor 做了 context engineering，精準管理上下文。 

在背後編排多次 LLM call，

組成複雜的 DAG。 提供應用專屬的 GUI，

設計人機協作介面。 提供 autonomy slider，

讓自動化程度可調整。 

仔細平衡每個環節的成本與效能。



Karpathy 在 Y Combinator 演講中強調：

LLM labs 訓練出通用的大學畢業生。

 LLM apps 組織它們、微調它們，透過提供私有資料、

感測器、執行器和回饋迴路，

把它們變成特定垂直領域的專業團隊。

任務要拆成可控的 pipeline，

每段都有清楚的輸入、輸出、驗證、fallback。 

LLM 產品的飛輪不會自然形成，

要主動把使用者回饋工程化成可用的優化訊號。



關鍵問題：垂直任務適合拆成什麼樣的 pipeline？

 每個節點的驗證機制是什麼？ 

如何把使用者回饋工程化成模型優化訊號？ 

護城河到底是什麼，

會不會被模型廠商內建功能吃掉？



編排的厚度，決定了價值。

---





▋ AI 住在客戶環境裡

Claude Code 在 2025 年展示了 LLM Agent 的新範式。

 它直接在使用者電腦上執行，

不是在雲端容器跑。

Karpathy 認為 OpenAI 搞錯了順序。

 他們把早期的 codex 和 agent 努力放在從 ChatGPT 編排的雲端容器部署，

而非 [localhost](localhost)。

關鍵的區別不是「AI ops 跑在哪」。

 是其他一切：已經開機的電腦、現成的安裝環境、

上下文、資料、密鑰、配置，以及低延遲互動。

Anthropic 把 Claude Code 包裝成極簡的 CLI 形式。

 它是一個「住」在電腦上的小精靈、小幽靈。

對垂直應用來說，

最缺的往往是接進客戶現場的工具鏈與資料鏈。

 權限、密鑰、內網、舊系統整合。

「住在客戶環境」會成為降低採用門檻的關鍵，

也是建立企業信任的設計點。 

CLI、本機 sidecar 有時比 SaaS 更快被接受。



關鍵問題：

垂直 agent 最適合的部署形態是什麼？ 如

何在「就地取材」與「可管理性」間取平衡？

 如何把「低延遲互動」量化成產品指標？



Form factor 是採用策略。

---

▋ 程式變便宜，規格與驗證變昂貴

2025 年，AI 跨越了門檻，

任何人都能用英文生成複雜程式。

 Karpathy 創造了「vibe coding」這個詞。

Vibe coding 讓一般人也能程式設計，

也讓專業人士寫更多「本來不會寫」的程式。

Karpathy 舉了自己的例子。 在 nanochat 專案中，

他 vibe coded 了一個高效的 BPE tokenizer用 Rust 寫。 

不用採用現成函式庫，

也不用真的學到那個深度的 Rust。 

他 vibe coded 了很多快速 app demo，

像是 menugen、llm-council、reader3。 

甚至 vibe coded 整個臨時 app 就為了找一個 bug。

程式碼變得免費、臨時、可塑、用完即丟。



團隊分工要往這些方向移動：

任務設計、評測、風控、整合、觀測。

 產品策略要敢用「一次性小工具」換洞察與速度，

但要有治理邊界。



關鍵問題：團隊應該把資源重新分配到哪些能力？

 哪些任務適合用一次性工具快速驗證？界線在哪？

 如何建立「可丟棄程式碼」的治理框架？



程式碼變便宜了，判斷力變貴了。

---





▋ 下一代介面是視覺工作台

Google Gemini 的 Nano Banana 是 2025 年最令人驚豔的模型之一。 

在 Karpathy 的世界觀裡，

LLM 是下一個主要的運算範式，就像 1970、80 年代的電腦。

跟 LLM「聊天」有點像 1980 年代對電腦主機下指令。

 文字是電腦（和 LLM）偏好的原始資料格式，

但不是人類偏好的格式。

人們其實不喜歡讀文字，讀文字又慢又費力。 

人們喜歡視覺化和空間化地吸收資訊。 

這就是傳統運算發明 GUI 的原因。



LLM 應該用人們偏好的格式說話：

圖片、資訊圖表、投影片、白板、動畫、影片、web app。

Nano Banana 不只是圖像生成本身。

 重要的是聯合能力：文字生成、圖像生成、

世界知識，全部糾纏在模型權重裡。

垂直領域的 LLM GUI 讓使用者用更少文字就能指定需求。

 圈選、塗抹、拖拉、時間軸、地圖、流程圖。 

產品形態會從「問答系統」轉變成「可操作的工作台」。



關鍵問題：

垂直任務中，哪些天然不適合 chat，

適合用圖表、白板、時間軸來互動？ 

如何把「文字生成視覺產物」做成可迭代互動？ 

Nano Banana 式的能力（圈選、塗鴉式指令）對領域意味著什麼？



介面是認知槓桿。

---

▋ 給垂直 AI 產品開發者的 5 個關鍵問題

如果只能問 5 個問題，就問這些：

．任務哪 10% 最值錢，且能做成可驗證閉環？（決定能不能做出飛輪）

．如何建立回歸測試集，確保模型升級不打爆產品？（決定能不能長期活下去）

．成熟的 context engineering 需要哪些可觀測性與驗證流程？（決定是不是只是在堆 RAG）

．護城河到底是什麼？哪些會被模型廠商內建功能吃掉？（決定是不是在做必死題）

．該用什麼 form factor（本機、CLI、sidecar、web）才能最快嵌入客戶環境？（決定能不能被採用）

---





▋ 機會窗口還很大

2025 年的 LLM 進展既驚人又令人困惑。 

它們同時比預期更聰明，也比預期更愚蠢。

但可以確定的是，

即使在當前能力下，

產業還沒發揮出 10% 的潛力。

 Karpathy 說，

他同時相信會看到快速持續的進展，也相信還有很多工作要做。

對於垂直 AI 產品開發者，

機會窗口還很大。 

護城河要建立在工程能力、

評測體系和客戶整合上。

概念上，

這個領域完全開放，

有太多想法可以嘗試。


