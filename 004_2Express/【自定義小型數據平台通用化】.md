---
tags:
  - my-article
Checkbox 1: true
---
【自定義小型數據平台通用化】

—— 打造通用且可快速複製的小型數據平台，降低數據建置成本並快速驗證新產品

備註：本文許多概念是參考 [Practical Lakehouse Architecture](https://learning.oreilly.com/library/view/practical-lakehouse-architecture/9781098153007/) 一書



開發新東西本質上是充滿不確定性的。



自從一年前轉往開發外部產品。



就面開始面臨較多的試誤過程。



個人是滿享受想產品、實作、驗證的過程。



只不過如果有些嘗試的部分成果是可重複使用。



那麼在試誤的過程中還可以順便打磨團隊能力。



以我們 Team 為例，大部分案件都包含數據搜集、處理、分析、應用。



因此我們持續在思考是否有一個可以快速建構的基礎數據平台架構。



讓新的嘗試方向都可以加速腳步，盡快到驗證狀態。





▋數據平台與一般系統差異

數據平台本質上就是一個讓數據可以發揮業務效益的系統架構。



如果說要跟一般應用系統區隔的話。



一般系統就像是門市，是功能與數據的組合，且完全以使用者為導向。



但數據平台比較像是一個工廠產線。



整個產線目的就是讓數據越來越有價值。



最終才會讓下游門市可以利用這些數據去產生業務價值。



例如，一般系統像是消費者用來點餐的 APP，而數據平台則像是處理顧客購買紀錄、預測顧客偏好的後台數據處理系統。



▋數據平台基礎組成

『 The data platform is the final result of implementing a data architecture using the chosen technology stack. 』



data lake、Data Warehouse、Lakehouse 都是屬於不同的技術堆疊而成的數據架構。



而數據架構其實是有一些通用性的不變原則。



例如 Data Lake 的核心元件常是廉價的對象存儲（如 Blob、S3），Lakehouse 則加入元數據管理（如 Delta Lake）。



其就像是建築物也有分鋼構、鋼筋混泥土、木屋…等，但梁柱結構的一些原則是通用的。



數據架構的藍圖裡，通常有遵循以下原則：

．**Defining core components**

．**Defining component interdependencies and data flow**

．**Defining guiding principles**

．**Defining the technology stack**



細節之後我再書的內容整理出來，這裡先用這原則來定義我們團隊的通用數據平台。





▋情境與目標

為了讓數據平台能適用於不同的專案，我們設定了幾個具體條件，作為團隊通用平台的基本框架：

．在即時性的要求上，不追求毫秒級的處理能力，而是將目標設定在約 5 至 10 秒內的資料延遲範圍內。

．以公司目前已採用的 Databricks 作為數據流程核心，並考量到客戶端環境的限制，地端程式要最大程度的通用。

．能夠支援大量數據分析場景，包括異常偵測、時間序列分析、數據探勘與機器學習等常見任務。

．基本應用形式將包含有權限管理的報表系統、即時通知服務以及數據傳輸模組。

．成本需合理控制，非必要的即時性需求以批次處理為主，以有效縮短運算時間、降低雲端費用。

．資料來源包含 Edge Computing 與 IoT 設備，因此需要考量數據傳輸的穩定性和多樣性。

．提供 Delta Table 的定期優化機制，以及成本效益高的數據備份策略。

由於公司的核心業務著重於各類「實體場域解決方案」，像是門市商店、辦公室、會議空間或汽車座艙等，因此整個數據 Pipeline 的成果，都必須易於被各種實體場域靈活使用。但不同場域在數據分析與應用目標上可能差異很大，因此我們初期將以較通用的模組與流程為主，例如：

．適用於多場景的通用廣告或商品推薦系統

．通用的汽車數據監控 + 電動車充電管理解決方案

後續再逐步思考如何將這些分析流程打造成標準化 Library，整合成更容易快速佈署的 Pipeline。

▋規劃內容

根據上述的情境目標，我們將團隊的通用數據架構規劃如下：



**\[ Data ingestion（資料攝取）\]**

．對即時性要求最高的資料來源，會以 EventHub 或類似的即時串流工具為主。

．非嚴格即時（秒級以上）資料攝取，使用 Databricks 的 Auto Loader 完成。

．批次資料統一由 Databricks Pipeline 處理。

．為了降低資料遺失風險及成本效益考量，所有資料皆會先儲存於原始存儲（如 Azure Blob 或 AWS S3），再交由 Databricks 處理。



**\[Data Processing（資料處理與分析）\]**

．基本處理邏輯皆以 Spark 框架搭配 Python 實作，形成可快速部署的 PySpark 模組。

．資料分析核心模組，會開發通用的異常偵測、數據探勘和機器學習 Library，供多種專案重複使用。

．在時間序列分析方面，因 Spark 架構的特性，我們主要使用 Spark 內建的 Window function 處理數據切分等邏輯；而較複雜的模型（如 ARIMA、VAR）則透過 Python 套件搭配 Spark UDF 進行大規模運算。

．Delta Table 定期優化（如 OPTIMIZE 指令、Liquid Clustering）及備份到低成本儲存（如冷儲存）的策略。

．Pipeline 的管理將透過 Databricks Workflow 進行統一的控制與監測。



**\[地端執行環境支援\]**

．由於 Delta Lake、Spark 和 Python 均有地端版本，地端環境的分析程式原則上可完整複製雲端架構，以維持最大化的程式碼重用性。



**\[前後端系統\]**

．資料庫：目前在 Azure 環境使用 Azure SQL，在其他雲端或地端受限於成本則可能改為 PostgreSQL。

．後端服務：使用 [ASP.NET](ASP.NET) Core (.NET 8) 搭建含權限管理模組的報表服務後端，主要考量是團隊的既有經驗與維護的便利性。

．前端 Portal：選擇 Vue.js 作為前端框架，以團隊熟悉度與開發效率為考量。



**\[報表服務\]**

．針對 UI 設計需求不迫切的情境，會優先使用 Databricks Dashboard，搭配權限管理功能直接整合到 Vue.js 前端。

．若需更靈活且有定制化 UI 的需求，暫時使用 Python Dash 開發快速原型。

---

透過這樣的規劃，儘管仍有不少技術細節需要摸索與調整，但只要架構持續打磨，未來面對新業務需求時，團隊能夠更迅速且高效地推出有價值的產品，並逐步累積團隊的核心競爭力。



▋挑戰

1. 分析通用:  不同業務分析通用性有點難，因此我們用 Library 以外，還期望可以有一些通用流程出來，例如根據數據性質給予異常分析監控，然後自動抓取異常數據進行相關性分析

2. 成本管控: 雲端會需要盡可能最小化運算時間，以便控制成本在一定的範圍內，而這牽扯到很多的嘗試。

3. 地端的檔案服務、資源管理 Infra vm 自己建立



—— 

範疇感覺不大的資料架構，其執行起來就需要花很多時間構想嘗試。



更不用提各種不同需求的變形。



但只要技術有所累積，讓未來開發更快速，一切都會很值得。


