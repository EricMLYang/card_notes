---
tags:
  - my-article
Checkbox 1: true
---
【嘗試用 Ultralearning 概念來攻破 Databricks Pro 考綱】



最近團隊收到一個任務。

配合公司政策，被要求去考 3 星證照。

全名是 Databricks Certified Data Engineer Professional。

這對我們來說有點挑戰。

時間比較趕。

專案也還在持續忙碌。

團隊裡還有純軟體工程背景的成員，

相對比較少數據實戰經驗。

這種情況，只好打團體戰了。

---



▋ 策略：如何學得快又好？

我們決定參考 Scott H. Young 的《Ultralearning》這本書。

想看看書中的方法，

是不是真的可以實踐。

書裡主要提到了九大法則：

後設學習 (meta learning)、專心、直截了當、

反覆操練、提取記憶、回饋、

保留、直覺，以及實驗。

我們第一步，

就是用 meta learning (後設學習) 的概念來拆解考試內容。

---



▋ 拆解 (一)：學什麼？

第一步，先把所有要學的內容，

分成三種類型：

1\.Concepts (概念)：你必須要理解知道的。

2\.Facts (事實)：那些必須要記住的。

3\.Procedures (程序)：需要持續練習的。

這讓我們清楚定義了「What」，也就是要學什麼。

---



▋ 拆解 (二)：依 80/20 原則重組

接著，我們看考綱的 10 個主題。

依照 80/20 原則，

把他們重組為 7 個「作戰集群」：

．核心開發與轉換 (32%): 包含 \[數據轉換、清洗和品質 (10%)\]

．維運與自動化 (20%): 由 \[監控與警報 (10%)\] + \[除錯與部署 (10%)\] 組成

．安全與治理 (17%): 由 \[確保數據安全與合規 (10%)\] + \[數據治理 (7%)\] 組成

．成本與效能優化 (13%): \[成本與性能優化 (13%)\]

．數據攝取 (7%): \[數據攝取與獲取 (7%)\]

．數據建模 (6%): \[數據建模 (6%)\]

．數據共享 (5%): \[數據共享與聯邦 (5%)\]

我們發現，真正的拉分差距，

在於「維運 (20%)」、「安全 (17%)」和「優化 (13%)」。

這三塊加起來剛好 50%，

是區分「工程師」與「專業工程師」的關鍵。

---



▋ 拆解 (三)：How (怎麼學)

定義好學什麼之後，

接著是「怎麼學」。

我們要求一次只專注於一個最小學習單元。

然後依循這三步驟，

攻克一個特定主題：

1\.學習：

花 20-30 分鐘閱讀文章或觀看影片，

先求理解概念。



2,實作：

花 30-60 分鐘，

直接在 Databricks 中針對該概念，

進行動手編碼或解決問題。



3\.回想與測驗 (Recall & Quiz)：

花 10 分鐘，

透過自製閃卡或自我提問，

進行主動回憶，鞏固關鍵知識。

這就是我們的學習循環。

---



▋ 概念地圖 (一)：整體架構

為了讓大家快速上手，

我們整理了最精簡的概念地圖。



．Medallion Architecture:

將資料組織成銅 (原始)、銀 (清理) 和金 (業務) 三層，

逐步提升品質。



．模組化 ETL:

將管線分階段、模組化，

提高重用性與可維護性。



．Spark 轉換與動作:

利用 Spark 的延遲執行特性，

建構轉換 (Transformations) 計畫，

並透過動作 (Actions) 觸發運算。



．Delta Lake 可靠性:

透過 ACID 交易、結構強制和時間旅行 (Time Travel)，

確保資料的可靠性與版本控制。



．效能調校:

透過分區、Z-Ordering 或液態叢集 (Liquid Clustering) 減少資料掃描，

並使用 OPTIMIZE 合併小檔案。



．串流 vs. 批次:

結構化串流處理即時資料，

(Auto Loader 簡化攝取)；

批次處理用於週期性作業。



．資料品質與治理:

使用 DLT 期望 (Expectations) 驗證品質；

使用 Unity Catalog (UC) 統一管理權限、稽核與血緣。



．任務調度 & CI/CD:

使用 Jobs 自動化排程，

並透過 Repos (Git) 和 Asset Bundles (IaC) 實作 CI/CD。

這些是整體的核心觀念。

---



▋ 概念地圖 (二)：各考綱主題

接著，是針對 10 個考綱主題(這裡放最濃縮版本）：

1\.(開發): Spark 採延遲執行。

應優先使用內建函數，避免效能低落的 UDF。

2\.(攝取): Auto Loader 是自動化、增量處理雲端新檔案的標準，

能處理結構演進。

3\.(轉換/品質): 採 ELT 模式。

DLT 是聲明式框架，用「期望」內建資料品質檢查。

4\.(共享/聯邦): Delta Sharing「不複製」地分享即時資料；

Lakehouse Federation「查詢」外部資料庫。

5\.(監控): 依需求使用 Spark UI (Job 除錯)、

Query Profile (SQL 除錯)、System Tables (審計) 和 SQL Alerts (指標)。

6\.(效能): OPTIMIZE 合併小檔案；

Liquid Clustering 優化資料佈局；Photon 引擎加速運算。

7\.(安全): Unity Catalog (UC) 統一管理三層命名空間權限、

行級安全與列級遮罩。

8\.(治理): UC 自動提供數據目錄、

欄位級數據血緣和標籤 (Tags) 功能。

9\.(部署): Repos 整合 Git 版控；

Asset Bundles (DABs) 透過 YAML 檔定義並部署管線。

10\.(建模): Medallion (銅/銀/金) 是基礎。

Gold 層常使用星型模型，優化 BI 查詢。



---



▋ 記憶：必須記住的 Facts

再來是「Facts 事實」類型。

我們用「Q → A」列出高頻且容易混淆的知識點。

以 C.1: 開發 (Facts) 2題為例：



**repartition() 和 coalesce() 的區別？**

A:

 repartition() 會產生完整的 Shuffle，

可增加或減少 Partitions；

coalesce() 僅用於「減少」Partitions，

它會合併現有的 Partitions，避免完整 Shuffle，速度較快。



**為什麼 PySpark UDF 效能差？**

A: 

Python <-> JVM 序列化/反序列化成本。

破壞 Catalyst Optimizer 優化（它對 UDF 內部是黑盒子）。



這些細節是拿分的關鍵。

---



▋ 實戰：要持續練習的 Procedures

最後是「Procedures 程序」。

我們出了 10 多題小主題，

模擬真實情境。

例如，

一個常見的程序：「評估 Table 狀態」。

要檢查的是檔案數量、平均檔案大小和碎片化程度。

如果你看到成千上萬個小檔案，

或許多未優化的分區，

這就是你接著要優化的目標。



最後，

我們把會陸續把詳細知識放到 Heptabase 的白板，

讓大家都可以看得到，

期望能提高一點考過機率。




