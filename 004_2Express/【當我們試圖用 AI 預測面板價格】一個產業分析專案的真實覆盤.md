---
tags:
  - my-article
  - published
pipeline_stage: "DONE"
topic: "AI 產業分析：面板下游產業的 LLM 應用專案"
scenario: "case_study"
created: 2026-02-20
published: 2026-02-20
status: "published"
---

# 當我們試圖用 AI 預測面板價格：一個產業分析專案的真實覆盤
ㅤ
「預測面板價格」——這五個字，在我們部門幾乎等同於「聖杯」。
ㅤ
每個季度，主管們盯著報表問：「下個月的價格會怎麼走？」而我們只能摸摸鼻子，丟出一堆假設和模型。說實話，準確率跟擲骰子差不多。
ㅤ
直到 ChatGPT 3.5 問世，我們開始想：如果讓 AI 來讀新聞、看研報，會不會比我們更快抓到市場風向？
ㅤ
這篇文章，是那個專案的真實覆盤。有成果，有踩坑，也有現在回頭看才懂的反思。
ㅤ
ㅤ
▋ 專案的起點，是從預測面板價格這個聖杯開始
ㅤ
大型語言模型（LLM）的時代才剛揭開幕後，ChatGPT 3.5 的出現，為一切帶來了新的可能性。
ㅤ
當時，公司內部正在推動一個名為「MI 2.0」的專案，目標是整合昂貴的市場研究數據，再加上我們自己爬蟲蒐集的總體經濟數據與電商資訊，希望藉此建構出更具洞察力的分析報表。
ㅤ
我們最初的野心，是挑戰那個業界的聖杯：預測面板價格。
ㅤ
然而，這很快就被證明是一項極度困難的任務。因此，專案的方向悄然轉變，我們開始嘗試結合新聞、產業報告等非結構化資訊，希望能從中找到輔助分析的線索。
ㅤ
這個專案名義上雖是產業分析，但核心更偏向動態追蹤。它始終圍繞著面板價格預測這個主軸，並延伸至對下游產業——電視、筆電、車用市場的觀察。
ㅤ
回頭來看，在那個 AI 工具剛問世的階段，我們的方法或許帶了點「炫技」的色彩，總想著如何把這個新工具用得淋漓盡致。但現在看來，或許我們應該更專注於分析的本質。
ㅤ
這個專案的核心，是試圖在數據與瞬息萬變的市場之間，找到一條新的連結路徑。
ㅤ
ㅤ
▋ 數據有其極限，市場的劇變需要更即時的資訊
ㅤ
我們替公司內部的 TV、NB、DT，以及中國車用等多個 BU 處理了大量的研調與爬蟲數據，也做了許多分析與預測模型。
ㅤ
但我們很快就發現，單純處理數字，有著嚴重的侷限性。在市場變化劇烈的時候，數據的更新速度，遠遠跟不上現實的腳步。
ㅤ
BU 需要更快的資訊來應對變局，例如即時的新聞。
ㅤ
像是「8 月的 CCI（消費者信心指數）上升了，市場會提前復甦嗎？」
或是「9 月美國 GDP 下修幅度很大，復甦會不會因此延後？」
甚至，「終端產品價格大幅跳水了，這會不會刺激需求提前湧現？」
ㅤ
這些問題，都無法單靠落後的數據回答。因此，我們希望將新聞資訊萃取出來，並配合過去在數據分析中建立的因果關係，例如「庫存水位會影響面板價格」這樣的模型，對未來做出更敏銳的推論。
ㅤ
我們試圖在傳統的數據分析之上，嫁接一層來自市場前線的即時情報網。
ㅤ
ㅤ
▋ 為了讓機器讀懂新聞，我們設計了兩道 GPT 處理流程
ㅤ
為了讓 AI 能理解龐雜的資訊，我們必須先教會它如何分類與萃取。
ㅤ
我們從「議題」出發，由相關部門的專家們，共同列出了我們關注的面板下游產業議題，涵蓋了電視、筆電、電腦螢幕、車用等領域。
ㅤ
這些議題被歸納到大約 10 個主要方向，其中包括了：
ㅤ
區域(市場)法規
消費者
客戶(車廠)的議價能力
產品開發與替代品
生態圈與新進者
現有競爭者的動態
生產製造
成本與供應商的議價能力
ㅤ
每一則新聞進來，都會先通過第一道 GPT。它的任務是判斷新聞內容是否與我們設定的重要議題相關。
ㅤ
一旦確認相關，這則新聞就會進入第二道 GPT。這次的任務更為精細，它要像做「命名實體辨識 (Named-entity recognition)」一樣，把內文中的關鍵元素和它們之間的「關係」抓出來。
ㅤ
例如，一句「戴爾取消美光記憶體下單」，會被拆解成「戴爾 (公司) 下單 美光 (公司)」，以及「美光 (公司) 生產 記憶體 (產品)」這樣的結構化資訊。
ㅤ
這些被萃取出來的元素與關係，會被儲存到資料庫裡，成為我們未來用來串連、比對數據的重要基礎。
ㅤ
這套流程的核心，是將非結構化的文字，轉化為機器能夠理解並分析的結構化知識。
ㅤ
ㅤ
▋ 從藍圖到實踐：駕馭決策風險的 AI 協作模式
ㅤ
為了讓 AI 的分析能夠真正落地，我們擘劃了一套從數據到決策的完整分析藍圖。這條路徑從最原始的數據開始：
ㅤ
1. 數據 → 圖表：透過基本的統計分析與視覺化工具，將冰冷的數字轉化為可供觀察的圖表。
ㅤ
2. 資訊–現象：從圖表中，我們觀察並識別出值得注意的現象，例如「某個趨勢正在上升」。
ㅤ
3. 資訊–關係：接著，我們深入探討現象之間的關聯，試圖從「相關性」中，找出潛在的「因果關係」。
ㅤ
4. 分析架構：然後，我們套用成熟的商業分析模型，如「波特五力分析」或「策略 3C」，來建構一個有邏輯的分析框架。
ㅤ
5. 情境論述：在這個框架下，我們進行「What if」的情境模擬與假設分析，用以預測或推演未來的可能性。
ㅤ
6. 敘述分析：最後，我們將所有分析結果，轉化為一個易於理解的「故事 (Story)」，向決策者清楚地陳述我們的洞見。
ㅤ
7. 決策：這個故事，最終將成為支持管理層做出決策的關鍵依據。
ㅤ
然而，這套看似完美的藍圖，在現實中充滿了人性偏誤的陷阱。我們必須警惕使用者如何解讀 AI 提供的資訊，這就是「推理階梯（Ladder of Inference）」給我們的啟示。
ㅤ
讓我們想像一個情境：一位電視業務主管，看到了系統生成的報告。他從觀察數據到採取行動的過程可能是：
ㅤ
第 1 階：觀察數據
AI 系統呈現事實：越南提供新補貼、55 吋面板報價下跌 5%、競爭對手 S 公司在越南市佔率成長 3%、我方銷售額持平。
ㅤ
第 2 階：選擇性接收
他的注意力，立刻被「對手市佔率成長」和「我方銷售額持平」的負面資訊給吸住，卻忽略了「面板報價下跌」的利好消息。
ㅤ
第 3-7 階：快速跳躍
他迅速將資訊解讀為「我們正失去競爭力」，並跳躍式地假設「對手一定是在降價」，最終形成「必須立即跟進降價」的結論與信念，要求團隊投入價格戰。
ㅤ
最大的跳躍發生在，他基於片面資訊，直接做出了「對手在降價」的假設，卻沒有任何驗證。那個被忽略的「面板報價下跌」資訊，本來可以成為我們在不犧牲利潤下，進行策略性促銷的絕佳機會。
ㅤ
這給了我們深刻的啟發：AI 系統不應只是「資訊呈現者」，更該扮演「推理階梯的引導者」。它應該主動挑戰選擇性接收、協助使用者揭示並檢驗假設，甚至利用 AI Agent 提供多元觀點。
ㅤ
為了將這套分析藍圖落地，並有效引導使用者避開推理階梯的陷阱，我們設計了一套仰賴 AI 模擬專家的人機協作模式。為了模擬真實世界的專業分工，我們讓 AI 扮演了整個分析團隊的角色。
ㅤ
整個流程始於議題的設定：
ㅤ
1. 議題／目標設定：由人類專案經理（PM）提出明確的分析議題或目標，為整個專案定調。
ㅤ
2. AI 專家團隊收集資訊：接著，我們透過設計不同的 Prompt，驅動 LLM 扮演各種領域的專家，分頭收集並整理資料。這個虛擬團隊包括：
ㅤ
AI 汽車數據分析師
AI 總經專家
AI 財報專家
AI 智慧座艙專家
AI 電動車（EV）趨勢專家
AI 車用軟體專家
ㅤ
3. AI 商業產品分析師：我們再用一個新的 Prompt，讓 LLM 扮演總分析師的角色，基於前面「專家們」提供的多元資訊，進行全面的商業與產品分析，萃取出核心洞見。
ㅤ
4. AI 作家撰寫報告：接著由扮演「作家」的 LLM 接手，將複雜的分析結果，轉化為邏輯清晰、表達精準的文字報告。
ㅤ
5. 人類查核員審閱：最後，報告會交由人類查核員進行最終審閱，確保所有數據的正確性與邏輯的一致性，才能正式輸出。
ㅤ
這個流程強調了從「議題」到「AI 生成資料」，再到「AI 分析」、「AI 敘事」，最後回到「人類審核」的完整閉環。這套「人機協作」的模式，是為了在確保效率的同時，也能兼顧報告的深度、準確度與決策參考價值。
ㅤ
ㅤ
▋ 我們打造了全新的 AI 輔助工作流，實現議題分析的自動化
ㅤ
為了提升效率，我們設計了一套全新的 AI 輔助資料處理 Pipeline。
ㅤ
這個流程是這樣運作的：
ㅤ
1. 文字輸入：流程的起點是大量的原始內容，來源可以是純文字、文件檔案，或是網路新聞。
ㅤ
2. 生成摘要 (Summary)：內容會先被送入 LLM（例如 ChatGPT）進行處理，快速生成摘要，並存入「summary table」。
ㅤ
3. 議題擷取：系統會自動從摘要中提取核心議題，並將其寫入獨立的「議題 Table」，後續的處理都將圍繞這些議題展開。
ㅤ
4. 更新片段：針對每個議題，系統會持續擷取最新的相關消息段落，保持資訊的即時性。
ㅤ
5. 元素分析：接著，系統會從這些消息中，提取出更細緻的關鍵元素，像是公司、事件、數據、趨勢等，並建立一個「元素 Table」。
ㅤ
6. 元素連結：最關鍵的一步，是利用 LLM 的能力，將資料庫中相同或相似的元素自動關聯起來，整合成一個完整的知識脈絡。
ㅤ
最終，這些被串連起來的資訊，可以直接用於生成報告，或輸出成 HTML 格式的網頁。
ㅤ
為了確保數據品質，我們還設計了查重機制：
ㅤ
消息查重：透過比對「近期資料」加上「Embedding 相似度」，來判斷是否為重複的新聞。
ㅤ
元素查重：同樣利用「初始資料」加上「Embedding 相似度」，來檢查是否有相似的元素，避免重複記錄。
ㅤ
這是一條以 AI 為核心，結合 Embedding 相似度與知識鏈結的智能化議題分析流程。
ㅤ
ㅤ
▋ AI 的核心能力，在於自動從文本中抽取關鍵的實體關係
ㅤ
這整個新流程的技術核心，在於實現了「實體關係抽取（Entity Relationship Extraction）」的自動化。
ㅤ
AI 不再只是閱讀文字，它學會了理解文字背後的結構與關聯。它能從一句話中，辨識出誰是主角、誰是配角，以及他們之間發生了什麼事。
ㅤ
就像拼圖一樣，AI 將從成千上萬篇報導中提取出的零散「實體」與「關係」，自動拼接成一張宏大的產業知識圖譜。
ㅤ
這項技術，正是我們能夠將海量非結構化資訊，轉化為結構化洞見的關鍵。
ㅤ
ㅤ
▋ 覆盤：這個專案教會我的事
ㅤ
回頭看這個專案，最大的收穫不是技術，而是認知上的轉變。
ㅤ
第一，AI 不是萬能的，但它能放大你的分析能力。
我們試圖讓 AI 預測價格失敗了，但讓它協助我們整理、分類、萃取資訊卻成功了。找對 AI 的位置，比什麼功能都重要。
ㅤ
第二，人機協作的關鍵，在於設計好「人類介入點」。
最終判斷、邏輯核查、決策責任，這些永遠該留給人類。AI 是好幫手，但不是好老闆。
ㅤ
第三，數據不等於洞見，脈絡才是。
單一數字毫無意義，當你把「戴爾」、「下單」、「美光」串連起來，才開始有了故事。這也是為什麼我們投入這麼多心力在「實體關係抽取」上。
ㅤ
這個專案讓我理解：AI 時代，真正稀缺的能力，不是寫程式、不是下 Prompt——而是設計問題、建構脈絡、做出判斷。
ㅤ
技術會進步，工具會迭代。但那些關於「如何思考」的經驗，會一直跟著你。
