# 4-AI Coding 的實用邊界：認知範圍決定協作上限

**類型**：Warning

## 概念

AI Coding 的實用性受限於使用者的認知範圍。當 AI 產出的代碼或架構「遠超出使用者認知」，以至於使用者無法判斷正確性、無法找到問題、無法修正錯誤時，協作就會中斷。這不是 AI 能力的問題，而是「責任與驗證能力」的限制——你必須能理解並為產出負責，否則無法在生產環境使用，更無法說服團隊或客戶。這類似投資建議：當建議超出你的理解，你就無法承擔風險或說服他人投入資源。

## 重要性

避免對 AI Coding 抱持不切實際的期待，幫助判斷「什麼任務適合 AI 輔助」「什麼需要先學習再用 AI」。

## 邊界/反例

並非所有超出認知的內容都不能用。關鍵在於「能否快速學習並驗證」——如果 AI 產出的代碼雖然陌生但可以透過文檔、測試快速理解，仍可使用。反之，若涉及複雜架構決策（如分散式系統設計、安全模型），超出認知就很危險。此外，在「探索性專案」或「低風險環境」（如個人練習），可以更大膽使用超出認知的方案。

## 標籤

#AICoding #認知邊界 #責任 #協作限制 #工具使用
